{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a4a268",
   "metadata": {},
   "source": [
    "### Setup Jupyter notebook\n",
    "Setup Jupyter notebook to use (Python) modules in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a26b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/InServiceOfX\n",
      "Is CoreCode directory in sys.path? False\n",
      "Is notebook directory's ancestor in sys.path? False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Make this path be the project's \"base\" directory, so we can include modules\n",
    "notebook_directory_ancestor = Path.cwd().resolve().parent.parent.parent\n",
    "print(notebook_directory_ancestor)\n",
    "core_code_directory = notebook_directory_ancestor / \"CoreCode/\"\n",
    "is_core_code_directory_in_sys_path = str(core_code_directory) in sys.path\n",
    "is_notebook_directory_ancestor_in_sys_path = str(notebook_directory_ancestor) in sys.path\n",
    "print(\"Is CoreCode directory in sys.path?\", is_core_code_directory_in_sys_path)\n",
    "print(\"Is notebook directory's ancestor in sys.path?\", is_notebook_directory_ancestor_in_sys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see your current sys.path\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9fdd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_core_code_directory_in_sys_path:\n",
    "    sys.path.append(str(core_code_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03feb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoreCode.Utilities.LoadEnvironmentFile import load_environment_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b84f5d",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/get_started/quickstart\n",
    "\n",
    "# Large Language Model (LLM) Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c53feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to set an environment variable\n",
    "import os\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual OpenAI API key\n",
    "# os.environ['OPENAI_API_KEY'] = 'your_api_key_here'\n",
    "# Instead, use our load_environment_file method.\n",
    "load_environment_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment out if you want to show you obtained your key.\n",
    "# open_ai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# Uncomment out to show your key\n",
    "# print(open_ai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764f409",
   "metadata": {},
   "source": [
    "We can then initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a74eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "# Uncomment out to print the help file.\n",
    "# print(help(ChatOpenAI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d518b189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can help with testing in several ways:\\n\\n1. Test Data Generation: Langsmith can automatically generate a large amount of test data based on the specifications provided. This helps in testing the application's ability to handle different types of inputs and scenarios.\\n\\n2. Test Case Generation: Langsmith can generate test cases based on the application's requirements or specifications. It helps in ensuring that all possible scenarios and edge cases are covered during testing.\\n\\n3. Test Automation: Langsmith can automate the execution of test cases, saving time and effort for manual testers. It can also integrate with existing testing frameworks and tools to streamline the testing process.\\n\\n4. Test Coverage Analysis: Langsmith can analyze the coverage of test cases against the application's codebase. It helps in identifying areas of the code that are not adequately tested and ensures comprehensive test coverage.\\n\\n5. Bug Detection: Langsmith can assist in detecting bugs and vulnerabilities in the application by performing automated code analysis. It can identify potential issues, such as memory leaks, null pointer dereferences, or security vulnerabilities, which can be addressed during testing.\\n\\n6. Performance Testing: Langsmith can simulate various load and stress scenarios to test the performance and scalability of the application. It helps in identifying performance bottlenecks and ensuring that the application can handle the expected workload.\\n\\nOverall, Langsmith's capabilities in data generation, test case generation, automation, coverage analysis, bug detection, and performance testing contribute to more efficient and effective testing processes.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a02640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59613eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4edbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae93e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith is a powerful tool that can greatly assist with testing in various ways. Here are some ways in which Langsmith can help with testing:\\n\\n1. Test Case Management: Langsmith provides a platform to manage test cases effectively. It allows you to create, organize, and track test cases, making it easier to manage and execute tests.\\n\\n2. Test Data Generation: Langsmith can generate realistic and diverse test data to ensure comprehensive testing. By automatically generating test data, you can cover a wide range of scenarios and edge cases, improving the overall quality of your testing.\\n\\n3. Test Automation: With Langsmith, you can automate the execution of test cases, saving time and effort. It helps in reducing manual effort, improving test coverage, and ensuring consistent test execution.\\n\\n4. Test Result Analysis: Langsmith provides detailed test result analysis, allowing you to identify patterns, trends, and potential issues. It offers various reporting and visualization capabilities, enabling you to gain insights into the test results and make data-driven decisions.\\n\\n5. Integration with Testing Frameworks: Langsmith can integrate with popular testing frameworks, such as Selenium or JUnit, to streamline the testing process. This integration allows you to leverage the existing testing infrastructure and frameworks while benefiting from Langsmith's additional features.\\n\\n6. Collaboration and Communication: Langsmith facilitates collaboration between testers, developers, and stakeholders. It provides a centralized platform for sharing test cases, test results, and other testing artifacts, ensuring effective communication and collaboration throughout the testing process.\\n\\n7. Continuous Testing: Langsmith supports continuous testing practices by integrating with CI/CD pipelines. It enables automated testing at each stage of the development lifecycle, ensuring early detection of issues and faster feedback loops.\\n\\nOverall, Langsmith can help streamline and optimize testing processes, improve test coverage, and enhance the overall quality of your software.\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca657ae",
   "metadata": {},
   "source": [
    "## Diving Deeper\n",
    "\n",
    "Consider the basics of prompts, models, output parsers - [documentation](https://python.langchain.com/docs/modules/model_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb85146",
   "metadata": {},
   "source": [
    "# Retrieval Chain\n",
    "\n",
    "Say we need to provide additional context to the LLM. Retrieval is useful when you have too much data to pass to the LLM directly. Then use a retriever to fetch only the most relevant pieces and pass those in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24936b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4bcf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.document_loaders.web_base.WebBaseLoader'>\n",
      "CPU times: user 4.57 ms, sys: 156 Âµs, total: 4.73 ms\n",
      "Wall time: 3.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "print(type(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a146d43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "CPU times: user 161 ms, sys: 0 ns, total: 161 ms\n",
      "Wall time: 5.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs = loader.load()\n",
    "print(type(docs))\n",
    "print(len(docs))\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c03ef6",
   "metadata": {},
   "source": [
    "Next, we need to index this data, document, into a vectorstore. This requires a few components, namely\n",
    "* [embedding model](https://python.langchain.com/docs/modules/data_connection/text_embedding)\n",
    "* [vectorstore](https://python.langchain.com/docs/modules/data_connection/vectorstores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78bf7ca",
   "metadata": {},
   "source": [
    "## Retrieval Chain, embedding, vectorstore, with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628b60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8021f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.embeddings.base.OpenAIEmbeddings'>\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19de58",
   "metadata": {},
   "source": [
    "Use this embedding model to ingest documents into a vectorstore. We'll use a simple local vectorstore,\n",
    "[FAISS](https://python.langchain.com/docs/integrations/vectorstores/faiss),\n",
    "for simplicity's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b76a041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6aa320c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/ThirdParty/langchain/libs/community/langchain_community/vectorstores/faiss.py:55\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[0;34m(no_avx2)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter()\n\u001b[1;32m      2\u001b[0m documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs)\n\u001b[0;32m----> 3\u001b[0m vector \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ThirdParty/langchain/libs/core/langchain_core/vectorstores.py:508\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    507\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ThirdParty/langchain/libs/community/langchain_community/vectorstores/faiss.py:960\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    959\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ThirdParty/langchain/libs/community/langchain_community/vectorstores/faiss.py:914\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[0;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__from\u001b[39m(\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    913\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m--> 914\u001b[0m     faiss \u001b[38;5;241m=\u001b[39m \u001b[43mdependable_faiss_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m distance_strategy \u001b[38;5;241m==\u001b[39m DistanceStrategy\u001b[38;5;241m.\u001b[39mMAX_INNER_PRODUCT:\n\u001b[1;32m    916\u001b[0m         index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m/ThirdParty/langchain/libs/community/langchain_community/vectorstores/faiss.py:57\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[0;34m(no_avx2)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import faiss python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install faiss-gpu` (for CUDA supported GPU) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m faiss\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version)."
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ce85c",
   "metadata": {},
   "source": [
    "# Debug, Scratch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(CoreCode.Utilities.ConfigurePaths.default_path_to_env_file()))\n",
    "print(CoreCode.Utilities.ConfigurePaths._setup_paths())\n",
    "print(str(Path(__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd51a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(Path(__file__)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
