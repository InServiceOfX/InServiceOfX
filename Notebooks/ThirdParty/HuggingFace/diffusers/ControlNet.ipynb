{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4496ef4b",
   "metadata": {},
   "source": [
    "### Local Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fc11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/InServiceOfX\n",
      "Is CoreCode directory in sys.path? False\n",
      "Is notebook directory's ancestor in sys.path? False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Make this path be the project's \"base\" directory, so we can include modules\n",
    "notebook_directory_ancestor = Path.cwd().resolve().parent.parent.parent.parent\n",
    "print(notebook_directory_ancestor)\n",
    "core_code_directory = notebook_directory_ancestor / \"PythonLibraries\" / \"CoreCode\"\n",
    "\n",
    "is_core_code_directory_in_sys_path = str(core_code_directory) in sys.path\n",
    "is_notebook_directory_ancestor_in_sys_path = str(notebook_directory_ancestor) in sys.path\n",
    "print(\"Is CoreCode directory in sys.path?\", is_core_code_directory_in_sys_path)\n",
    "print(\"Is notebook directory's ancestor in sys.path?\", is_notebook_directory_ancestor_in_sys_path)\n",
    "\n",
    "if not is_core_code_directory_in_sys_path:\n",
    "    sys.path.append(str(core_code_directory))\n",
    "    \n",
    "from corecode.Utilities import (\n",
    "    DataSubdirectories,\n",
    "    )\n",
    "data_sub_dirs = DataSubdirectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5d0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instant_id_path = notebook_directory_ancestor.parent / \"ThirdParty\" / \"InstantID\"\n",
    "if (instant_id_path.exists() and str(instant_id_path) not in sys.path):\n",
    "    sys.path.append(str(instant_id_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9442cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added MoreInsightFace\n"
     ]
    }
   ],
   "source": [
    "more_insight_face_directory = notebook_directory_ancestor / \"PythonLibraries\" / \"ThirdParties\" / \"MoreInsightFace\"\n",
    "if (more_insight_face_directory.exists() and str(more_insight_face_directory) not in sys.path):\n",
    "    sys.path.append(str(more_insight_face_directory))\n",
    "    print(\"added MoreInsightFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9aec025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "controlnet_path = data_sub_dirs.ModelsDiffusion / \"InstantX\" / \"InstantID\" / \"ControlNetModel\"\n",
    "print(controlnet_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09b056ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4ecc93f70d4a4ea42c1d40467a660a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers.models import ControlNetModel\n",
    "from diffusers.utils.torch_utils import is_compiled_module\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ef127",
   "metadata": {},
   "source": [
    "If you make this torch_dtype=torch.float16 for ControlNet, then at when InstantID's StableDiffusionXL... class calls .encode_prompt(..), this error is obtained below. This is because if we choose .to(\"cuda\"), we run out of VRAM on our local GPU. But if we choose \"cpu\" or \"cpu offloading\", because the CPU doesn't know the type float16 nor know how to process it, it'll result in this.\n",
    "```\n",
    "File /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2548, in layer_norm(input, normalized_shape, weight, bias, eps)\n",
    "   2544 if has_torch_function_variadic(input, weight, bias):\n",
    "   2545     return handle_torch_function(\n",
    "   2546         layer_norm, (input, weight, bias), input, normalized_shape, weight=weight, bias=bias, eps=eps\n",
    "   2547     )\n",
    "-> 2548 return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
    "\n",
    "RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5666a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See diffusers/models/controlnet.py and __init__(..)\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    controlnet_path,\n",
    "    #torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ae3532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(controlnet, ControlNetModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc99fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_compiled_module in module diffusers.utils.torch_utils:\n",
      "\n",
      "is_compiled_module(module) -> bool\n",
      "    Check whether the module was compiled with torch.compile()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(is_compiled_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47983f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_compiled_module(controlnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c393d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict([('in_channels', 4),\n",
       "            ('conditioning_channels', 3),\n",
       "            ('flip_sin_to_cos', True),\n",
       "            ('freq_shift', 0),\n",
       "            ('down_block_types',\n",
       "             ['DownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D']),\n",
       "            ('mid_block_type', 'UNetMidBlock2DCrossAttn'),\n",
       "            ('only_cross_attention', False),\n",
       "            ('block_out_channels', [320, 640, 1280]),\n",
       "            ('layers_per_block', 2),\n",
       "            ('downsample_padding', 1),\n",
       "            ('mid_block_scale_factor', 1),\n",
       "            ('act_fn', 'silu'),\n",
       "            ('norm_num_groups', 32),\n",
       "            ('norm_eps', 1e-05),\n",
       "            ('cross_attention_dim', 2048),\n",
       "            ('transformer_layers_per_block', [1, 2, 10]),\n",
       "            ('encoder_hid_dim', None),\n",
       "            ('encoder_hid_dim_type', None),\n",
       "            ('attention_head_dim', [5, 10, 20]),\n",
       "            ('num_attention_heads', None),\n",
       "            ('use_linear_projection', True),\n",
       "            ('class_embed_type', None),\n",
       "            ('addition_embed_type', 'text_time'),\n",
       "            ('addition_time_embed_dim', 256),\n",
       "            ('num_class_embeds', None),\n",
       "            ('upcast_attention', None),\n",
       "            ('resnet_time_scale_shift', 'default'),\n",
       "            ('projection_class_embeddings_input_dim', 2816),\n",
       "            ('controlnet_conditioning_channel_order', 'rgb'),\n",
       "            ('conditioning_embedding_out_channels', [16, 32, 96, 256]),\n",
       "            ('global_pool_conditions', False),\n",
       "            ('addition_embed_type_num_heads', 64),\n",
       "            ('_use_default_values', ['mid_block_type']),\n",
       "            ('_class_name', 'ControlNetModel'),\n",
       "            ('_diffusers_version', '0.21.2'),\n",
       "            ('_name_or_path',\n",
       "             PosixPath('/Data/Models/Diffusion/InstantX/InstantID/ControlNetModel'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b80f6737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.config.global_pool_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53b4fed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54639edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_stable_diffusion_xl_instantid import StableDiffusionXLInstantIDPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09325b",
   "metadata": {},
   "source": [
    "self.do_classifier_free_guidance is not defined as a class member that is inherited in, say, an __init__() or a class member function, rather, it is decorated with @property as a class member function that takes as input `self`. This property is not inherited, but manually copied for each Python class that needs it.\n",
    "\n",
    "See for example pipeline_stable_diffusion_xl.py in pipelines/stable_diffusion_xl of diffusers, but there are multiple examples of this.\n",
    "\n",
    "Recall that \n",
    "```\n",
    "    @property\n",
    "    def do_classifier_free_guidance(self):\n",
    "        return self._guidance_scale > 1 and self.unet.config.time_cond_proj_dim is None\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60118d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StableDiffusionXLInstantIDPipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mStableDiffusionXLInstantIDPipeline\u001b[49m\u001b[38;5;241m.\u001b[39mdo_classifier_free_guidance\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StableDiffusionXLInstantIDPipeline' is not defined"
     ]
    }
   ],
   "source": [
    "StableDiffusionXLInstantIDPipeline.do_classifier_free_guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10595c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model_subdir = data_sub_dirs.ModelsDiffusion / \"fluently\" / \"Fluently-XL-v4\"\n",
    "print(model_subdir)\n",
    "print(model_subdir.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab9f9b",
   "metadata": {},
   "source": [
    "For torch_dtype, *if* you set torch_dtype=torch.float16, the device has to be \"cuda\" and not \"cpu\" because otherwise, you get the error:\n",
    "\n",
    "```\n",
    "-> 2548 return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
    "\n",
    "RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00eaff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488c5e00f44941b0860cccd124570c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  scheduler\n",
      "{}\n",
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  text_encoder\n",
      "{'torch_dtype': None, 'device_map': None, 'max_memory': None, 'offload_folder': None, 'offload_state_dict': False, 'low_cpu_mem_usage': True}\n",
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  tokenizer\n",
      "{}\n",
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  text_encoder_2\n",
      "{'torch_dtype': None, 'device_map': None, 'max_memory': None, 'offload_folder': None, 'offload_state_dict': False, 'low_cpu_mem_usage': True}\n",
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  vae\n",
      "{'torch_dtype': None, 'device_map': None, 'max_memory': None, 'offload_folder': None, 'offload_state_dict': False, 'variant': None, 'low_cpu_mem_usage': True}\n",
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  tokenizer_2\n",
      "{}\n",
      "cached_folder:  /Data/Models/Diffusion/fluently/Fluently-XL-v4\n",
      "name:  unet\n",
      "{'torch_dtype': None, 'device_map': None, 'max_memory': None, 'offload_folder': None, 'offload_state_dict': False, 'variant': None, 'low_cpu_mem_usage': True}\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "pipe = StableDiffusionXLInstantIDPipeline.from_pretrained(\n",
    "    str(model_subdir),\n",
    "    controlnet=controlnet,\n",
    "    #revision=\"fp16\",\n",
    "    # If workload is CPU or offloaded to CPU, can't allow this type.\n",
    "    #torch_dtype=torch.float16,\n",
    "    local_files_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf6cb56",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 35.44 MiB is free. Process 99163 has 6.58 GiB memory in use. Of the allocated memory 6.24 GiB is allocated by PyTorch, and 214.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ThirdParty/diffusers/src/diffusers/pipelines/pipeline_utils.py:427\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been loaded in 8bit and moving it to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m via `.to()` is not yet supported. Module is still on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    430\u001b[0m     module\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silence_dtype_warnings\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_offloaded\n\u001b[1;32m    434\u001b[0m ):\n\u001b[1;32m    435\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1151\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1148\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:801\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 801\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:801\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 801\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 801 (6 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:801\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 801\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:824\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 824\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1149\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1148\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 35.44 MiB is free. Process 99163 has 6.58 GiB memory in use. Of the allocated memory 6.24 GiB is allocated by PyTorch, and 214.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#pipe.to(\"cuda\")\n",
    "\n",
    "\"\"\"\n",
    "I obtained this error:\n",
    "\n",
    "OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 35.44 MiB is free. Process 99163 has 6.58 GiB memory in use. Of the allocated memory 6.24 GiB is allocated by PyTorch, and 214.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3a652",
   "metadata": {},
   "source": [
    "The attribute `self._guidance_scale` and therefore also properties `do_classifier_free_guidance` only come into existence on a `__call__` call, see pipelines/controlnet/pipeline_controlnet_sd_xl.py and `__call__` function definition for the class. Also notice that do_classifier_free_guidance is defined as a class member function and decorated with a `@property` - treat this as syntactic sugar at a rudimentary level.\n",
    "\n",
    "Also, note that guidance scale comes in as an optional parameter in the call function, with default value at 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1c8914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttributeError\n",
    "# AttributeError: 'StableDiffusionXLInstantIDPipeline' object has no attribute '_guidance_scale'\n",
    "#print(pipe.do_classifier_free_guidance)\n",
    "#print(type(pipe.do_classifier_free_guidance))\n",
    "#print(pipe._guidance_scale())\n",
    "#print(type(pipe._guidance_scale))\n",
    "\n",
    "# AttributeError: 'StableDiffusionXLInstantIDPipeline' object has no attribute '_guidance_scale'\n",
    "#StableDiffusionXLInstantIDPipeline.do_classifier_free_guidance.__get__(pipe)\n",
    "\n",
    "#AttributeError: 'StableDiffusionXLInstantIDPipeline' object has no attribute '_guidance_scale'\n",
    "#StableDiffusionXLInstantIDPipeline.guidance_scale.__get__(pipe)\n",
    "\n",
    "# AttributeError: 'StableDiffusionXLInstantIDPipeline' object has no attribute '_guidance_scale'\n",
    "#pipe._guidance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "987edc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(pipe.unet.config.time_cond_proj_dim)\n",
    "print(type(pipe.unet.config.time_cond_proj_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10343e87",
   "metadata": {},
   "source": [
    "guess_mode is default False in `__call__` in pipeline_stable_diffusion_xl_instantid.py of InstantID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "623f13a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<class 'bool'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "global_pool_conditions = (\n",
    "    controlnet.config.global_pool_conditions\n",
    "    if isinstance(controlnet, ControlNetModel)\n",
    "    else controlnet.nets[0].config.global_pool_conditions)\n",
    "print(global_pool_conditions)\n",
    "print(type(global_pool_conditions))\n",
    "guess_mode = False\n",
    "guess_mode = guess_mode or global_pool_conditions\n",
    "print(guess_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fe7e3",
   "metadata": {},
   "source": [
    "Recall in InstantID.pipeline_stable_diffusion_xl_instantid.py,\n",
    "\n",
    "```\n",
    "    @torch.no_grad()\n",
    "    @replace_example_docstring(EXAMPLE_DOC_STRING)\n",
    "    def __call__(\n",
    "        self,\n",
    "        prompt: Union[str, List[str]] = None,\n",
    "        prompt_2: Optional[Union[str, List[str]]] = None,\n",
    "        image: PipelineImageInput = None,\n",
    "        height: Optional[int] = None,\n",
    "        width: Optional[int] = None,\n",
    "        num_inference_steps: int = 50,\n",
    "        guidance_scale: float = 5.0,\n",
    "        negative_prompt: Optional[Union[str, List[str]]] = None,\n",
    "        negative_prompt_2: Optional[Union[str, List[str]]] = None,\n",
    "        num_images_per_prompt: Optional[int] = 1,\n",
    "        eta: float = 0.0,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        latents: Optional[torch.FloatTensor] = None,\n",
    "        prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        negative_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        pooled_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        negative_pooled_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        image_embeds: Optional[torch.FloatTensor] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        controlnet_conditioning_scale: Union[float, List[float]] = 1.0,\n",
    "        guess_mode: bool = False,\n",
    "        control_guidance_start: Union[float, List[float]] = 0.0,\n",
    "        control_guidance_end: Union[float, List[float]] = 1.0,\n",
    "        original_size: Tuple[int, int] = None,\n",
    "        crops_coords_top_left: Tuple[int, int] = (0, 0),\n",
    "        target_size: Tuple[int, int] = None,\n",
    "        negative_original_size: Optional[Tuple[int, int]] = None,\n",
    "        negative_crops_coords_top_left: Tuple[int, int] = (0, 0),\n",
    "        negative_target_size: Optional[Tuple[int, int]] = None,\n",
    "        clip_skip: Optional[int] = None,\n",
    "        callback_on_step_end: Optional[Callable[[int, int, Dict], None]] = None,\n",
    "        callback_on_step_end_tensor_inputs: List[str] = [\"latents\"],\n",
    "\n",
    "        # IP adapter\n",
    "        ip_adapter_scale=None,\n",
    "\n",
    "        **kwargs,\n",
    "    ):\n",
    "```\n",
    "and\n",
    "\n",
    "```\n",
    "\t\timages = pipe(\n",
    "\t\t\tprompt=prompt,\n",
    "\t\t\tnegative_prompt=negative_prompt,\n",
    "\t\t\timage_embeds=face_information.face_embedding,\n",
    "            # keypoints are from a \"pose\" image\n",
    "            image=keypoints,\n",
    "\t\t\tcontrolnet_conditioning_scale=float(controlnet_conditioning_scale),\n",
    "\t\t\tnum_inference_steps=number_of_steps,\n",
    "            # Height, width are both from the \"pose\" image\n",
    "            height=height,\n",
    "\t\t\twidth=width).images\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efdb01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moreinsightface.Wrappers import get_face_and_pose_info_from_images#FaceAnalysisWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aadceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ThirdParty/insightface/python-package/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    }
   ],
   "source": [
    "original_default_det_result = get_face_and_pose_info_from_images(\n",
    "    \"antelopev2\",\n",
    "    \"/Data/Models/Diffusion/InstantX\",\n",
    "    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"LennaSjööblom_LenaForsén\" / \"qShFGgyfM2o8OTptV6bGyf_9QVDc7x2ua38DJyWci9nsRi8u2ZJunn27MMP8vji6wZmUna5cR7TDxpC_p1wrzVinINlkVsl8tB6JY3RF81L9bAU38H4N-EQwDtEWWUT2.jpeg\",\n",
    "    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"TeddiSmith\" / \"tumblr_oythctEdBF1wykvxvo1_1280.jpg\",\n",
    "    det_size=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c185c4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FaceInformation(face_embedding=array([-2.19255030e-01, -4.89995956e-01,  3.46210822e-02,  8.99958313e-01,\n",
       "        -1.32275462e+00, -1.37653565e+00,  4.01281342e-02,  3.18349041e-02,\n",
       "        -2.38527536e-01,  3.02093150e-03, -2.91089982e-01,  1.53613031e+00,\n",
       "        -8.68161678e-01, -1.37864041e+00, -1.28862226e+00,  6.11500219e-02,\n",
       "        -5.59473693e-01, -1.99329153e-01, -3.25344861e-01, -6.15891218e-01,\n",
       "        -2.01442385e+00,  7.32915044e-01,  1.88947833e+00, -2.76678298e-02,\n",
       "        -6.77791595e-01, -2.62548566e-01, -6.97107315e-01, -1.68059945e+00,\n",
       "         1.85134113e+00, -1.02117407e+00, -5.34121692e-01,  3.48018467e-01,\n",
       "         3.59841108e-01, -5.53745508e-01,  1.05247176e+00,  2.58443832e-01,\n",
       "        -1.02241564e+00, -7.81964898e-01, -1.46076393e+00, -5.42179942e-01,\n",
       "         6.76389098e-01, -1.02049577e+00,  5.61810732e-01, -1.35541391e+00,\n",
       "        -1.43527448e+00,  6.03798367e-02, -1.34801853e+00,  1.86807171e-01,\n",
       "         5.03632128e-02,  2.38811076e-01,  3.92950267e-01,  9.08821046e-01,\n",
       "         4.19378519e-01,  1.88432527e+00, -6.12239778e-01,  8.59245285e-02,\n",
       "        -9.60320532e-01, -1.04918599e+00,  6.67272925e-01,  1.61659491e+00,\n",
       "         1.38918948e+00, -4.20341501e-03,  1.57762301e+00,  8.53487730e-01,\n",
       "         6.89497054e-01, -2.87210912e-01, -7.11992800e-01,  4.87799138e-01,\n",
       "         4.59862947e-01, -5.45318425e-01, -5.45656621e-01,  2.15923476e+00,\n",
       "        -1.31609225e+00, -1.33425796e+00,  1.60033143e+00,  1.21114090e-01,\n",
       "        -9.36291337e-01,  7.90690258e-02, -5.85477889e-01,  2.99118701e-02,\n",
       "         5.54185748e-01,  1.34335983e+00, -1.12434745e+00,  1.07416105e+00,\n",
       "        -1.66452801e+00,  6.40750647e-01, -4.38436478e-01,  9.97125566e-01,\n",
       "        -1.21095526e+00, -9.81388092e-01,  6.27444148e-01, -5.51299512e-01,\n",
       "         1.35422540e+00,  2.50433415e-01, -1.25361645e+00, -3.18825096e-01,\n",
       "        -1.28002250e+00,  3.46007496e-01, -9.10154223e-01, -2.46594906e-01,\n",
       "         6.96880221e-01, -7.62074769e-01,  1.28779840e+00, -5.66711247e-01,\n",
       "         1.92813814e+00,  4.41078484e-01, -9.50900257e-01,  2.29283905e+00,\n",
       "         4.17309135e-01, -2.07509780e+00, -6.90376520e-01, -8.96730900e-01,\n",
       "        -4.61370528e-01,  2.29244804e+00,  2.57115483e-01, -1.70198429e+00,\n",
       "        -1.41706359e+00, -3.01215071e-02, -1.31019890e+00,  5.79264201e-03,\n",
       "         9.65498835e-02, -3.47733468e-01, -5.34568667e-01, -4.72754568e-01,\n",
       "         1.14216411e+00,  4.15238768e-01,  8.12901556e-01,  5.05309366e-02,\n",
       "         4.04835016e-01,  8.31877172e-01, -1.12355852e+00,  1.52223557e-01,\n",
       "        -1.34501302e+00,  4.68973368e-01,  9.23493430e-02, -1.67321754e+00,\n",
       "         2.94336855e-01, -1.24905145e+00,  1.49071038e+00,  1.29760849e+00,\n",
       "        -6.07582591e-02, -8.50163043e-01, -6.31153703e-01, -1.91670403e-01,\n",
       "        -2.70510226e-01,  1.07619965e+00,  1.44389784e+00, -1.34020388e+00,\n",
       "        -4.28788155e-01,  2.52822172e-02,  1.08029854e+00,  1.13957882e-01,\n",
       "         1.15507936e+00, -1.01107144e+00, -1.86720073e+00,  1.89627588e-01,\n",
       "         1.09877229e+00,  6.48612320e-01, -1.10318351e+00,  9.82584536e-01,\n",
       "         5.83692372e-01,  1.69273421e-01,  4.01721179e-01, -3.92089516e-01,\n",
       "        -3.90524596e-01,  8.08402836e-01,  7.04920471e-01,  4.76853549e-01,\n",
       "         1.02413930e-01, -3.91515851e-01, -5.72513163e-01, -1.10959306e-01,\n",
       "        -9.41434085e-01,  8.63053322e-01,  4.15779889e-01, -7.81412125e-01,\n",
       "         1.38765526e+00,  5.88993192e-01,  9.57278758e-02,  1.57994103e+00,\n",
       "         4.04428571e-01,  7.28563011e-01, -8.90352547e-01, -1.36052287e+00,\n",
       "        -6.52179956e-01, -4.70740438e-01, -5.84003806e-01, -1.16113342e-01,\n",
       "         1.30750144e+00, -2.53217131e-01, -9.49726030e-02,  4.58247028e-02,\n",
       "         1.35337889e+00, -1.14208639e+00, -7.05273986e-01,  2.94202399e+00,\n",
       "        -3.95861059e-01,  4.45184618e-01,  1.60500252e+00, -1.79787025e-01,\n",
       "        -5.14648557e-01,  4.89522368e-01, -1.00396693e+00, -7.91358232e-01,\n",
       "         1.05960488e+00, -4.49479610e-01,  2.28998733e+00,  8.61462355e-01,\n",
       "         2.78694296e+00, -9.61460590e-01,  7.21205235e-01,  3.60171348e-01,\n",
       "         3.67384195e-01,  1.45205781e-01, -2.12111264e-01, -1.87632814e-01,\n",
       "         1.42426240e+00,  9.42402184e-01, -1.38983771e-01, -4.85742651e-02,\n",
       "         2.42412820e-01,  1.97554219e+00,  1.81788361e+00, -1.54930925e+00,\n",
       "         1.46789658e+00,  6.89804316e-01,  1.66778058e-01, -1.17211390e+00,\n",
       "        -1.34676385e+00, -1.64059973e+00,  5.53291678e-01,  1.44535851e+00,\n",
       "         6.28634393e-01,  1.80125606e+00,  2.29675427e-01,  7.70810366e-01,\n",
       "         4.07801181e-01,  8.90783072e-01, -6.75384223e-01, -1.79543221e+00,\n",
       "        -8.69628116e-02,  2.80687064e-02, -1.75561774e+00,  1.36006624e-01,\n",
       "         1.09303260e+00, -4.87824649e-01, -1.75990915e+00, -5.92461407e-01,\n",
       "         7.94773936e-01,  1.12694240e+00,  1.65618730e+00, -1.65629327e+00,\n",
       "        -9.02624488e-01,  2.57579148e-01,  1.30294943e+00, -1.46645799e-01,\n",
       "         2.34347641e-01,  1.18601888e-01,  8.00372422e-01, -8.30759525e-01,\n",
       "         1.38097203e+00,  4.92904723e-01, -1.21162462e+00, -1.77816236e+00,\n",
       "        -2.76424199e-01, -3.57678866e+00,  2.03908235e-02, -4.20297146e-01,\n",
       "         3.54990959e-01, -1.50826359e+00, -1.00487635e-01, -7.17710793e-01,\n",
       "         9.03092742e-01, -5.61587036e-01, -2.36494392e-01, -3.04857945e+00,\n",
       "        -2.03860566e-01,  1.46585284e-02, -6.64184332e-01,  2.20943737e+00,\n",
       "        -6.33867621e-01,  1.70168984e+00, -6.68681264e-01, -1.14974785e+00,\n",
       "        -2.02617908e+00,  5.00671089e-01, -4.83491391e-01, -8.22129011e-01,\n",
       "         2.69631326e-01,  2.11190373e-01, -4.51269358e-01, -4.80459929e-01,\n",
       "        -1.21288991e+00,  1.94096565e+00, -3.90692353e-01,  3.38470079e-02,\n",
       "         4.12987113e-01,  1.58660185e+00,  7.59859502e-01,  8.45584750e-01,\n",
       "        -1.18222976e+00, -1.62422287e+00,  9.21403989e-03, -9.39758122e-01,\n",
       "         8.39898229e-01,  1.85313299e-01,  2.75614232e-01,  4.27088052e-01,\n",
       "         7.30100572e-01, -2.14485860e+00,  6.41656101e-01,  8.25750589e-01,\n",
       "         2.45003309e-03,  1.23872089e+00,  3.76673371e-01,  9.32800889e-01,\n",
       "         1.00558966e-01, -1.21827662e+00,  3.76114249e-01, -1.07530989e-01,\n",
       "        -9.30605590e-01, -2.37744585e-01, -6.97243810e-01,  1.29192579e+00,\n",
       "        -4.86944951e-02, -1.72321570e+00, -2.32924059e-01,  9.40477073e-01,\n",
       "         1.12376761e+00,  1.01941514e+00, -2.65751272e-01,  3.02756429e-01,\n",
       "         1.21317589e+00, -1.29127324e+00,  6.47840083e-01, -1.34296370e+00,\n",
       "        -1.95516264e+00, -3.85523528e-01, -6.80251360e-01, -6.57484591e-01,\n",
       "        -1.00910139e+00,  1.99100241e-01, -6.63130432e-02, -9.21228409e-01,\n",
       "        -6.22193813e-01, -6.93436980e-01,  1.08305359e+00, -9.19605136e-01,\n",
       "        -6.43942714e-01, -1.32766306e-01, -1.24466634e+00,  4.80906785e-01,\n",
       "         1.41908336e+00,  8.70736897e-01,  7.23600388e-01, -1.29907835e+00,\n",
       "         4.76357043e-01, -1.30089253e-01, -2.68972307e-01,  6.79701939e-02,\n",
       "         9.24022079e-01,  1.33647716e+00,  4.22853053e-01,  6.77791476e-01,\n",
       "        -2.94801593e-01, -9.89940017e-02,  5.02966702e-01,  7.21709430e-01,\n",
       "        -5.66127896e-01, -7.24909782e-01, -7.84928620e-01, -1.60006487e+00,\n",
       "         1.01540112e+00,  4.20975119e-01,  6.90832198e-01, -1.69449195e-01,\n",
       "         2.01475143e+00, -3.10849249e-01, -1.39819336e+00,  1.85349357e+00,\n",
       "         4.04746411e-03,  1.33836520e+00,  1.02060204e-02, -2.96074152e-01,\n",
       "        -1.09981513e-02,  1.41409957e+00,  1.58128965e+00,  1.15660095e+00,\n",
       "        -3.18333767e-02,  3.51792514e-01, -1.04311407e+00,  7.39248097e-01,\n",
       "        -1.18413496e+00, -3.46834511e-02, -4.33979958e-01, -1.27196148e-01,\n",
       "        -8.38805497e-01, -1.68051869e-01,  1.17199697e-01,  5.97573876e-01,\n",
       "        -3.01271170e-01,  3.23788524e-01, -4.83009249e-01,  5.37215710e-01,\n",
       "        -9.13453281e-01,  6.14306271e-01, -3.55532438e-01,  1.85434133e-01,\n",
       "         1.78601313e+00,  5.95191002e-01, -1.92774400e-01, -7.48507857e-01,\n",
       "         1.62880611e+00, -1.76570773e+00,  3.83193463e-01,  8.95709932e-01,\n",
       "         9.87910628e-01,  6.03100099e-02,  1.84833109e-02,  6.62289560e-01,\n",
       "         1.30548656e+00, -3.73976976e-01,  9.96821821e-02, -6.21643007e-01,\n",
       "        -1.36080131e-01,  4.01777625e-01, -9.33855176e-01,  2.15646958e+00,\n",
       "        -1.58727920e+00, -1.00269580e+00, -4.18664627e-02, -1.80360472e+00,\n",
       "        -1.31584883e+00, -1.11969662e+00,  1.04291809e+00,  3.09856355e-01,\n",
       "         1.50555015e-01, -7.80370057e-01, -5.03052995e-02,  6.79536283e-01,\n",
       "         7.03528762e-01,  1.15309209e-01, -2.73381889e-01, -5.21913707e-01,\n",
       "         1.69235003e+00, -4.81769815e-02,  1.10341299e+00,  1.39767659e+00,\n",
       "        -1.15154338e+00,  9.75187793e-02,  6.72150493e-01,  3.43847841e-01,\n",
       "         1.20454419e+00,  1.74035597e+00,  6.40208900e-01, -1.23131800e+00,\n",
       "        -5.16445279e-01,  4.92153943e-01,  5.66808820e-01, -3.21995735e-01,\n",
       "         5.56763172e-01, -1.13814786e-01,  7.78606087e-02,  3.85364264e-01,\n",
       "         1.50912881e+00,  9.37771738e-01, -5.02374947e-01,  4.22995649e-02,\n",
       "         8.79272580e-01,  1.21496117e+00, -1.60447288e+00,  4.93095398e-01,\n",
       "         5.97147584e-01, -2.70714313e-01,  2.81715572e-01,  1.10551633e-01,\n",
       "        -8.30646217e-01, -5.69178581e-01,  3.17947596e-01, -8.85572374e-01,\n",
       "         4.92810160e-01, -4.06129062e-01,  1.47657609e+00, -3.17416847e-01,\n",
       "        -1.84571600e+00, -4.70780969e-01, -3.47971052e-01,  1.17300496e-01,\n",
       "         1.38159007e-01,  2.56132841e-01,  3.45718235e-01,  3.99076104e-01,\n",
       "        -1.26304555e+00,  3.82348597e-01,  1.31872511e+00,  3.44468713e-01,\n",
       "         3.94605726e-01, -1.33504784e+00,  3.85922164e-01, -3.08401674e-01,\n",
       "        -1.69302809e+00,  1.67935061e+00, -1.12558532e+00, -3.77510339e-01,\n",
       "        -1.16738133e-01, -3.02768826e-01,  3.31506252e-01,  1.78257430e+00,\n",
       "        -1.87741423e+00, -1.59734118e+00, -1.58307958e+00, -1.79569900e+00],\n",
       "       dtype=float32), face_keypoints=<PIL.Image.Image image mode=RGB size=472x699 at 0x711A55DA7BB0>, height=699, width=472),\n",
       " PoseInformation(pose_keypoints=<PIL.Image.Image image mode=RGB size=773x800 at 0x711A55DA7B20>, height=800, width=773))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_default_det_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ffc9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512,)\n",
      "<class 'PIL.Image.Image'>\n",
      "<class 'int'>\n",
      "800\n",
      "<class 'int'>\n",
      "773\n"
     ]
    }
   ],
   "source": [
    "image_embeds = original_default_det_result[0].face_embedding\n",
    "print(type(image_embeds))\n",
    "print(image_embeds.shape)\n",
    "image_keypoints = original_default_det_result[1].pose_keypoints\n",
    "print(type(image_keypoints))\n",
    "height = original_default_det_result[1].height\n",
    "print(type(height))\n",
    "print(height)\n",
    "width = original_default_det_result[1].width\n",
    "print(type(width))\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd3a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.device'>\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#if prompt is not None and isinstance(prompt, str):\n",
    "batch_size = 1\n",
    "#default value in this input\n",
    "num_images_per_prompt = 1\n",
    "\n",
    "print(type(pipe._execution_device))\n",
    "print(pipe._execution_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a37899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://x.com/bri_guy_ai/status/1792915142096670830\n",
    "prompt=\"A pair of woman with black lipstick and futuristic eyewear wearing a matte leather techwear outfit is depicted in the style of street fashion photography., featuring architectural details like glass blocks and metal beams, shot on a Sony Alpha A7 III camera with an f/8 aperture setting.\"\n",
    "negative_prompt=\"(deformed iris, deformed pupils, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation, worst quality, low quality, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, beard, bearded face, facial hair, giant balloon boobs, double D breasts, (mutated hands and fingers:1.4)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6868302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 77, 2048])\n",
      "tensor([[[-3.7832, -2.3968,  4.3660,  ...,  0.1819,  0.3964, -0.2885],\n",
      "         [ 0.1400, -0.6531, -0.4755,  ...,  0.6230, -0.0515, -0.1875],\n",
      "         [ 1.2391, -1.2450,  0.2034,  ..., -0.0741,  0.6604,  0.3879],\n",
      "         ...,\n",
      "         [ 0.2431, -0.1541, -0.1018,  ..., -0.5995,  0.0151,  0.9838],\n",
      "         [ 0.2358, -0.1544, -0.1001,  ..., -0.6500, -0.0896,  1.0018],\n",
      "         [ 0.3099, -0.2136, -0.1878,  ..., -0.4197, -0.1246,  0.6815]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 77, 2048])\n",
      "tensor([[[-3.7832, -2.3968,  4.3660,  ...,  0.1819,  0.3964, -0.2885],\n",
      "         [-0.1023, -0.4413, -0.2958,  ...,  0.9558, -0.1419, -0.5040],\n",
      "         [ 0.6752,  0.1802, -0.0561,  ...,  0.0259,  0.4648,  0.0845],\n",
      "         ...,\n",
      "         [-0.5209, -0.7037, -0.1644,  ..., -0.0126, -0.2522,  0.0114],\n",
      "         [-0.6428, -0.2877,  1.2375,  ..., -0.0461,  0.2289, -0.0390],\n",
      "         [ 0.1557,  0.1864,  0.3326,  ...,  0.3965,  1.4452,  0.0896]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1280])\n",
      "tensor([[ 0.0714,  0.1062,  0.4999,  ..., -2.0968, -0.9834,  1.2613]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1280])\n",
      "tensor([[-1.8854, -1.0329,  0.7973,  ...,  0.1815, -0.0094, -0.1773]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFile /usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py:196, in LayerNorm.forward(self, input)\\n    195 def forward(self, input: Tensor) -> Tensor:\\n--> 196     return F.layer_norm(\\n    197         input, self.normalized_shape, self.weight, self.bias, self.eps)\\n\\nFile /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2548, in layer_norm(input, normalized_shape, weight, bias, eps)\\n   2544 if has_torch_function_variadic(input, weight, bias):\\n   2545     return handle_torch_function(\\n   2546         layer_norm, (input, weight, bias), input, normalized_shape, weight=weight, bias=bias, eps=eps\\n   2547     )\\n-> 2548 return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\\n\\nRuntimeError: \"LayerNormKernelImpl\" not implemented for \\'Half\\'\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Encode input prompt\n",
    "# Default value in input argument is None\n",
    "text_encoder_lora_scale = None\n",
    "(\n",
    "    prompt_embeds,\n",
    "    negative_prompt_embeds,\n",
    "    pooled_prompt_embeds,\n",
    "    negative_pooled_prompt_embeds,\n",
    ") = pipe.encode_prompt(\n",
    "    prompt,\n",
    "    # prompt_2 default value is None\n",
    "    None,\n",
    "    # device\n",
    "    pipe._execution_device,\n",
    "    num_images_per_prompt,\n",
    "    # self.do_classifier_free_guidance\n",
    "    True,\n",
    "    negative_prompt,\n",
    "    # negative_prompt_2\n",
    "    None,\n",
    "    prompt_embeds=None,\n",
    "    negative_prompt_embeds=None,\n",
    "    pooled_prompt_embeds=None,\n",
    "    lora_scale = None,\n",
    "    # clip_skip: Optional[int] = None in input arguments\n",
    "    clip_skip= None)\n",
    "print(type(prompt_embeds))\n",
    "print(prompt_embeds.size())\n",
    "print(prompt_embeds)\n",
    "print(type(negative_prompt_embeds))\n",
    "print(negative_prompt_embeds.size())\n",
    "print(negative_prompt_embeds)\n",
    "print(type(pooled_prompt_embeds))\n",
    "print(pooled_prompt_embeds.size())\n",
    "print(pooled_prompt_embeds)\n",
    "print(type(negative_pooled_prompt_embeds))\n",
    "print(negative_pooled_prompt_embeds.size())\n",
    "print(negative_pooled_prompt_embeds)\n",
    "\n",
    "# **IF** you set torch_dtype= float16, then the following is obtained:\n",
    "\"\"\"\n",
    "File /usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py:196, in LayerNorm.forward(self, input)\n",
    "    195 def forward(self, input: Tensor) -> Tensor:\n",
    "--> 196     return F.layer_norm(\n",
    "    197         input, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "\n",
    "File /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2548, in layer_norm(input, normalized_shape, weight, bias, eps)\n",
    "   2544 if has_torch_function_variadic(input, weight, bias):\n",
    "   2545     return handle_torch_function(\n",
    "   2546         layer_norm, (input, weight, bias), input, normalized_shape, weight=weight, bias=bias, eps=eps\n",
    "   2547     )\n",
    "-> 2548 return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
    "\n",
    "RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290068e",
   "metadata": {},
   "source": [
    "If you don't do the following, then when you run pipe._encode_prompt_image_emb (in pipeline_stable_diffusion_xl_instantid.py, look at def set_image_proj_model(..) for self.image_proj_model_in_features, you obtain \n",
    "\n",
    "```\n",
    "File /ThirdParty/diffusers/src/diffusers/configuration_utils.py:143, in ConfigMixin.__getattr__(self, name)\n",
    "    140     deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
    "    141     return self._internal_dict[name]\n",
    "--> 143 raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "\n",
    "AttributeError: 'StableDiffusionXLInstantIDPipeline' object has no attribute 'image_proj_model_in_features')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc39193",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_ip_adapter_instantid(\n",
    "    data_sub_dirs.ModelsDiffusion / \"InstantX\" / \"InstantID\" / \"ip-adapter.bin\",    \n",
    "    512,\n",
    "    16,\n",
    "    0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70fd2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(pipe.image_proj_model_in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe934dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 16, 2048])\n",
      "tensor([[[-0.0132,  0.0153, -0.0028],\n",
      "         [-0.0081,  0.0538, -0.0007]],\n",
      "\n",
      "        [[-0.0049,  0.0058, -0.0019],\n",
      "         [-0.0052,  0.0057, -0.0022]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Encode image prompt\n",
    "# Recall image_embeds is the details of the face.\n",
    "prompt_image_emb = pipe._encode_prompt_image_emb(image_embeds, \n",
    "                                                 device,\n",
    "                                                 num_images_per_prompt,\n",
    "                                                 pipe.unet.dtype,\n",
    "                                                 True)\n",
    "print(type(prompt_image_emb))\n",
    "print(prompt_image_emb.shape)\n",
    "print(prompt_image_emb[:,:2,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69ce2e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 4. Prepare image\n",
    "# Recall image comes in as an input into def __call__(..) and in InServiceOfX in generate_image.py, it's the\n",
    "# pose image keypoints.\n",
    "image = pipe.prepare_image(\n",
    "    image=image_keypoints,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    batch_size=batch_size * num_images_per_prompt,\n",
    "    num_images_per_prompt = num_images_per_prompt,\n",
    "    device=pipe._execution_device,\n",
    "    dtype=controlnet.dtype,\n",
    "    # True because guidance =5 >= 1 and unet config ... for this model is None.\n",
    "    do_classifier_free_guidance=True,\n",
    "    # guess_mode = guess_mode or global_pool_conditions\n",
    "    # guess_mode is None by default, and global_pool_conditions for this controlnet is None.\n",
    "    guess_mode = False \n",
    "    )\n",
    "\n",
    "print(type(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe46a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 800, 768])\n",
      "800\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(image.size())\n",
    "height, width = image.shape[-2:]\n",
    "print(height)\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eac009",
   "metadata": {},
   "source": [
    "latents is optional with default None in `__call__` for pipeline_stable_diffusion_xl_instantid.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2bc9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "<class 'torch.Tensor'>\n",
      "tensor([981., 961., 941.])\n"
     ]
    }
   ],
   "source": [
    "# 5. Prepare timesteps\n",
    "num_inference_steps = 50\n",
    "\n",
    "pipe.scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "timesteps = pipe.scheduler.timesteps\n",
    "\n",
    "print(len(timesteps))\n",
    "print(type(timesteps))\n",
    "print(timesteps[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "883ddea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "4\n",
      "torch.float32\n",
      "cpu\n",
      "torch.float32\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 6. Prepare latent variables, in pipeline_stable_diffusion_xl_instantid.py\n",
    "\n",
    "num_channels_latents = pipe.unet.config.in_channels\n",
    "print(type(num_channels_latents))\n",
    "print(num_channels_latents)\n",
    "print(prompt_embeds.dtype)\n",
    "device = pipe._execution_device\n",
    "print(device)\n",
    "print(controlnet.dtype)\n",
    "\n",
    "latents=None\n",
    "# Optional in __call__ of pipeline_stable_diffusion_xl_instantid.py, default value = None\n",
    "generator=None\n",
    "\n",
    "latents = pipe.prepare_latents(\n",
    "    batch_size * num_images_per_prompt,\n",
    "    num_channels_latents,\n",
    "    height,\n",
    "    width,\n",
    "    prompt_embeds.dtype,\n",
    "    device,\n",
    "    generator,\n",
    "    latents\n",
    ")\n",
    "\n",
    "print(type(latents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c982a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 100, 96])\n",
      "tensor([[[[ -4.0694,  35.3659],\n",
      "          [ 18.1392,  33.0154]],\n",
      "\n",
      "         [[ 18.4721,   6.8968],\n",
      "          [ 10.1103, -20.5980]],\n",
      "\n",
      "         [[-17.3097, -15.7112],\n",
      "          [ 16.0155,   2.6794]],\n",
      "\n",
      "         [[ 12.8094,  17.0525],\n",
      "          [  9.1987,   8.7587]]]])\n"
     ]
    }
   ],
   "source": [
    "print(latents.size())\n",
    "print(latents[:,:,:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc7e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.pipelines.controlnet.multicontrolnet import MultiControlNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d703ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_guidance_start isn't list, control_guidance_end isn't list\n",
      "[1.0]\n",
      "[0.0]\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Recall that these are input arguments into __call__(..) of pipeline_stable_diffusion_xl_instantid.py\n",
    "# control_guidance_start: Union[float, List[float]] = 0.0,\n",
    "# control_guidance_end: Union[float, List[float]] = 1.0,\n",
    "\n",
    "control_guidance_start = 0.0\n",
    "control_guidance_end = 1.0\n",
    "\n",
    "if not isinstance(control_guidance_start, list) and isinstance(control_guidance_end, list):\n",
    "    print(\"control_guidance_start isn't list, control_guidance_end is list\")\n",
    "    control_guidance_start = len(control_guidance_end) * [control_guidance_start]\n",
    "elif not isinstance(control_guidance_start, list) and not isinstance(control_guidance_end, list):\n",
    "    print(\"control_guidance_start isn't list, control_guidance_end isn't list\")\n",
    "    mult = len(controlnet.nets) if isinstance(controlnet, MultiControlNetModel) else 1\n",
    "    control_guidance_start, control_guidance_end = (\n",
    "        mult * [control_guidance_start],\n",
    "        mult * [control_guidance_end],\n",
    "    )\n",
    "#print(len(controlnet.nets))\n",
    "print(control_guidance_end)\n",
    "print(control_guidance_start)\n",
    "print(type(control_guidance_end))\n",
    "print(type(control_guidance_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f1b351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.0]\n",
      "1 [1.0]\n",
      "2 [1.0]\n",
      "3 [1.0]\n",
      "4 [1.0]\n",
      "5 [1.0]\n",
      "6 [1.0]\n",
      "7 [1.0]\n",
      "8 [1.0]\n",
      "9 [1.0]\n",
      "10 [1.0]\n",
      "11 [1.0]\n",
      "12 [1.0]\n",
      "13 [1.0]\n",
      "14 [1.0]\n",
      "15 [1.0]\n",
      "16 [1.0]\n",
      "17 [1.0]\n",
      "18 [1.0]\n",
      "19 [1.0]\n",
      "20 [1.0]\n",
      "21 [1.0]\n",
      "22 [1.0]\n",
      "23 [1.0]\n",
      "24 [1.0]\n",
      "25 [1.0]\n",
      "26 [1.0]\n",
      "27 [1.0]\n",
      "28 [1.0]\n",
      "29 [1.0]\n",
      "30 [1.0]\n",
      "31 [1.0]\n",
      "32 [1.0]\n",
      "33 [1.0]\n",
      "34 [1.0]\n",
      "35 [1.0]\n",
      "36 [1.0]\n",
      "37 [1.0]\n",
      "38 [1.0]\n",
      "39 [1.0]\n",
      "40 [1.0]\n",
      "41 [1.0]\n",
      "42 [1.0]\n",
      "43 [1.0]\n",
      "44 [1.0]\n",
      "45 [1.0]\n",
      "46 [1.0]\n",
      "47 [1.0]\n",
      "48 [1.0]\n",
      "49 [1.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Create tensor stating which controlnets to keep\n",
    "controlnet_keep = []\n",
    "for i in range(len(timesteps)):\n",
    "    keeps = [\n",
    "        1.0 - float(i/len(timesteps) < s or (i+1)/len(timesteps) > e)\n",
    "        for s, e in zip(control_guidance_start, control_guidance_end)\n",
    "    ]\n",
    "    print(i, keeps)\n",
    "    controlnet_keep.append(keeps[0] if isinstance(controlnet, ControlNetModel) else keeps)\n",
    "print(controlnet_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53f925bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 77, 2048])\n",
      "torch.Size([2, 16, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(prompt_embeds.shape)\n",
    "print(prompt_image_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "497c0c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Recall prompt_image_emb requires the IP Adapter, and is generated by _encode_prompt_image_embed\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# # Recall image_embeds is the details of the face.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m encoder_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_image_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# expand the latests if we are doing classifer free guidance\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Recall latests are ultimately from prompt embeddings + random values.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m latent_model_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([latests] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m latents\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Recall prompt_image_emb requires the IP Adapter, and is generated by _encode_prompt_image_embed\n",
    "# Recall image_embeds is the details of the face.\n",
    "encoder_hidden_states = torch.cat([prompt_embeds, prompt_image_emb], dim=1)\n",
    "\n",
    "# expand the latests if we are doing classifer free guidance\n",
    "# Recall latests are ultimately from prompt embeddings + random values.\n",
    "latent_model_input = torch.cat([latests] * 2) if True else latents\n",
    "print(type(latent_model_input))\n",
    "latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, timesteps[0])\n",
    "print(type(latent_model_input))\n",
    "\n",
    "control_model_input = latent_model_input\n",
    "print(type(control_model_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475dc2cb",
   "metadata": {},
   "source": [
    "Recall that in diffusers/src/diffusers/models/controlnet.py, in def forward(..) for ControlNetModel, which is called when `__call__(..)` is called (because ControlNetModel inherits from Pytorch's nn.Module), \n",
    "\n",
    "```\n",
    "    def forward(\n",
    "        self,\n",
    "        sample: torch.FloatTensor,\n",
    "        timestep: Union[torch.Tensor, float, int],\n",
    "        encoder_hidden_states: torch.Tensor,\n",
    "        controlnet_cond: torch.FloatTensor,\n",
    "        conditioning_scale: float = 1.0,\n",
    "        class_labels: Optional[torch.Tensor] = None,\n",
    "        timestep_cond: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        added_cond_kwargs: Optional[Dict[str, torch.Tensor]] = None,\n",
    "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        guess_mode: bool = False,\n",
    "        return_dict: bool = True,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38225e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 4, 100, 96])\n",
      "tensor([[[[-25.3158, -27.5542],\n",
      "          [ 20.7381,  -6.4022]],\n",
      "\n",
      "         [[-13.0147,   7.0481],\n",
      "          [-13.3508,  19.2171]]],\n",
      "\n",
      "\n",
      "        [[[-25.3158, -27.5542],\n",
      "          [ 20.7381,  -6.4022]],\n",
      "\n",
      "         [[-13.0147,   7.0481],\n",
      "          [-13.3508,  19.2171]]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 4, 100, 96])\n",
      "tensor([[[[-1.9239, -2.0940],\n",
      "          [ 1.5760, -0.4865]],\n",
      "\n",
      "         [[-0.9891,  0.5356],\n",
      "          [-1.0146,  1.4604]]],\n",
      "\n",
      "\n",
      "        [[[-1.9239, -2.0940],\n",
      "          [ 1.5760, -0.4865]],\n",
      "\n",
      "         [[-0.9891,  0.5356],\n",
      "          [-1.0146,  1.4604]]]])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 4, 100, 96])\n",
      "torch.Size([1, 77, 2048])\n"
     ]
    }
   ],
   "source": [
    "latent_model_input = torch.cat([latents] * 2) if True else latents\n",
    "print(type(latent_model_input))\n",
    "print(latent_model_input.shape)\n",
    "print(latent_model_input[:2, :2, :2, :2])\n",
    "latent_model_input = pipe.scheduler.scale_model_input(latent_model_input, timesteps[0])\n",
    "print(type(latent_model_input))\n",
    "print(latent_model_input.shape)\n",
    "print(latent_model_input[:2, :2, :2, :2])\n",
    "\n",
    "control_model_input = latent_model_input\n",
    "controlnet_prompt_embeds = prompt_embeds\n",
    "#controlnet_added_cond_kwargs = added_cond_kwargs\n",
    "print(type(control_model_input))\n",
    "print(type(controlnet_prompt_embeds))\n",
    "print(control_model_input.shape)\n",
    "print(controlnet_prompt_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f273fbd",
   "metadata": {},
   "source": [
    "Recall for `pipeline_stable_diffusion_xl_instantid.py`,\n",
    "\n",
    "```\n",
    "\n",
    "    @torch.no_grad()\n",
    "    @replace_example_docstring(EXAMPLE_DOC_STRING)\n",
    "    def __call__(\n",
    "        self,\n",
    "        prompt: Union[str, List[str]] = None,\n",
    "        prompt_2: Optional[Union[str, List[str]]] = None,\n",
    "        image: PipelineImageInput = None,\n",
    "        height: Optional[int] = None,\n",
    "        width: Optional[int] = None,\n",
    "        num_inference_steps: int = 50,\n",
    "        guidance_scale: float = 5.0,\n",
    "        negative_prompt: Optional[Union[str, List[str]]] = None,\n",
    "        negative_prompt_2: Optional[Union[str, List[str]]] = None,\n",
    "        num_images_per_prompt: Optional[int] = 1,\n",
    "        eta: float = 0.0,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        latents: Optional[torch.FloatTensor] = None,\n",
    "        prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        negative_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        pooled_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        negative_pooled_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
    "        image_embeds: Optional[torch.FloatTensor] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        controlnet_conditioning_scale: Union[float, List[float]] = 1.0,\n",
    "        guess_mode: bool = False,\n",
    "        control_guidance_start: Union[float, List[float]] = 0.0,\n",
    "        control_guidance_end: Union[float, List[float]] = 1.0,\n",
    "        original_size: Tuple[int, int] = None,\n",
    "        crops_coords_top_left: Tuple[int, int] = (0, 0),\n",
    "        target_size: Tuple[int, int] = None,\n",
    "        negative_original_size: Optional[Tuple[int, int]] = None,\n",
    "        negative_crops_coords_top_left: Tuple[int, int] = (0, 0),\n",
    "        negative_target_size: Optional[Tuple[int, int]] = None,\n",
    "        clip_skip: Optional[int] = None,\n",
    "        callback_on_step_end: Optional[Callable[[int, int, Dict], None]] = None,\n",
    "        callback_on_step_end_tensor_inputs: List[str] = [\"latents\"],\n",
    "\n",
    "        # IP adapter\n",
    "        ip_adapter_scale=None,\n",
    "\n",
    "        **kwargs,\n",
    "    ):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f6e9c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 768])\n",
      "(800, 768)\n"
     ]
    }
   ],
   "source": [
    "# default value of None in input arguments\n",
    "original_size = None\n",
    "# default value of (0, 0) in input arguments\n",
    "crops_coords_top_left = (0, 0)\n",
    "# default value None\n",
    "target_size = None\n",
    "\n",
    "# 7.2 Prepare added time ids & embeddings\n",
    "if isinstance(image, list):\n",
    "    original_size = original_size or image[0].shape[-2:]\n",
    "else:\n",
    "    original_size = original_size or image.shape[-2:]\n",
    "target_size = target_size or (height, width)\n",
    "\n",
    "print(original_size)\n",
    "print(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d91bf5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPTextModelWithProjection(\n",
      "  (text_model): CLIPTextTransformer(\n",
      "    (embeddings): CLIPTextEmbeddings(\n",
      "      (token_embedding): Embedding(49408, 1280)\n",
      "      (position_embedding): Embedding(77, 1280)\n",
      "    )\n",
      "    (encoder): CLIPEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x CLIPEncoderLayer(\n",
      "          (self_attn): CLIPAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layer_norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): CLIPMLP(\n",
      "            (activation_fn): GELUActivation()\n",
      "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          )\n",
      "          (layer_norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_projection): Linear(in_features=1280, out_features=1280, bias=False)\n",
      ")\n",
      "<class 'int'>\n",
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(pipe.text_encoder_2)\n",
    "if pipe.text_encoder_2 is None:\n",
    "    text_encoder_projection_dim = int(pooled_prompt_embeds.shape[-1])\n",
    "else:\n",
    "    text_encoder_projection_dim = pipe.text_encoder_2.config.projection_dim\n",
    "print(type(text_encoder_projection_dim))\n",
    "print(text_encoder_projection_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cfd484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 6])\n",
      "tensor([[800., 768.,   0.,   0., 800., 768.]])\n"
     ]
    }
   ],
   "source": [
    "add_time_ids = pipe._get_add_time_ids(\n",
    "    original_size,\n",
    "    crops_coords_top_left,\n",
    "    target_size,\n",
    "    dtype=prompt_embeds.dtype,\n",
    "    text_encoder_projection_dim=text_encoder_projection_dim,)\n",
    "print(type(add_time_ids))\n",
    "print(add_time_ids.shape)\n",
    "print(add_time_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d42773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 1280])\n"
     ]
    }
   ],
   "source": [
    "add_text_embeds = pooled_prompt_embeds\n",
    "#if self.do_classifier_free_guidance:\n",
    "if True:\n",
    "    #prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds], dim=0)\n",
    "    add_text_embeds = torch.cat([negative_pooled_prompt_embeds, add_text_embeds], dim=0)\n",
    "    #add_time_ids = torch.cat([negative_add_time_ids, add_time_ids], dim=0)\n",
    "print(type(add_text_embeds))\n",
    "print(add_text_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afac52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_cond_kwargs = {\"text_embeds\": add_text_embeds, \"time_ids\": add_time_ids}\n",
    "\n",
    "controlnet_added_cond_kwargs = added_cond_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9eb9d",
   "metadata": {},
   "source": [
    "Recall,\n",
    "```\n",
    "    def forward(\n",
    "        self,\n",
    "        sample: torch.FloatTensor,\n",
    "        timestep: Union[torch.Tensor, float, int],\n",
    "        encoder_hidden_states: torch.Tensor,\n",
    "        controlnet_cond: torch.FloatTensor,\n",
    "        conditioning_scale: float = 1.0,\n",
    "        class_labels: Optional[torch.Tensor] = None,\n",
    "        timestep_cond: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        added_cond_kwargs: Optional[Dict[str, torch.Tensor]] = None,\n",
    "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        guess_mode: bool = False,\n",
    "        return_dict: bool = True,\n",
    "    ) -> Union[ControlNetOutput, Tuple[Tuple[torch.FloatTensor, ...], torch.FloatTensor]]:\n",
    "```\n",
    "In diffusers/models/controlnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb983f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controlnet_conditioning_scale default to 1.0 as input argument to __call__(..). In my code, generate_image.py,\n",
    "# this is set for each image generation as a parameter.\n",
    "controlnet_keep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c0e267a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x2048 and 2816x1280)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m down_block_res_samples, mid_block_res_sample \u001b[38;5;241m=\u001b[39m \u001b[43mcontrolnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# latent_model_input, \u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Recall image_embeds is the details of the face.\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_image_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Recall image comes in as an input into def __call__(..) and in InServiceOfX in generate_image.py, it's the\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pose image keypoints.\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrolnet_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#conditioning_scale=cond_scale\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconditioning_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# added_cond_kwargs=controlnet_added_cond_kwargs\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrolnet_added_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ThirdParty/diffusers/src/diffusers/models/controlnet.py:793\u001b[0m, in \u001b[0;36mControlNetModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, controlnet_cond, conditioning_scale, class_labels, timestep_cond, attention_mask, added_cond_kwargs, cross_attention_kwargs, guess_mode, return_dict)\u001b[0m\n\u001b[1;32m    791\u001b[0m         add_embeds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([text_embeds, time_embeds], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    792\u001b[0m         add_embeds \u001b[38;5;241m=\u001b[39m add_embeds\u001b[38;5;241m.\u001b[39mto(emb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 793\u001b[0m         aug_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m emb \u001b[38;5;241m=\u001b[39m emb \u001b[38;5;241m+\u001b[39m aug_emb \u001b[38;5;28;01mif\u001b[39;00m aug_emb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m emb\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# 2. pre-process\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ThirdParty/diffusers/src/diffusers/models/embeddings.py:226\u001b[0m, in \u001b[0;36mTimestepEmbedding.forward\u001b[0;34m(self, sample, condition)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     sample \u001b[38;5;241m=\u001b[39m sample \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_proj(condition)\n\u001b[0;32m--> 226\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(sample)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x2048 and 2816x1280)"
     ]
    }
   ],
   "source": [
    "down_block_res_samples, mid_block_res_sample = controlnet(\n",
    "    # latent_model_input, \n",
    "    # Recall latests are ultimately from prompt embeddings + random values.\n",
    "    control_model_input,\n",
    "    timesteps[0],\n",
    "    # Recall image_embeds is the details of the face.\n",
    "    encoder_hidden_states=prompt_image_emb,\n",
    "    # Recall image comes in as an input into def __call__(..) and in InServiceOfX in generate_image.py, it's the\n",
    "    # pose image keypoints.\n",
    "    controlnet_cond=image,\n",
    "    #conditioning_scale=cond_scale\n",
    "    conditioning_scale=0.6,\n",
    "    # added_cond_kwargs=controlnet_added_cond_kwargs\n",
    "    added_cond_kwargs=controlnet_added_cond_kwargs,\n",
    "    return_dict=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb93c8a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m controlnet_results \u001b[38;5;241m=\u001b[39m \u001b[43mcontrolnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# latent_model_input, \u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Recall image_embeds is the details of the face.\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_image_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrolnet_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#conditioning_scale=cond_scale\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconditioning_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# added_cond_kwargs=controlnet_added_cond_kwargs\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#added_cond_kwargs=controlnet_added_cond_kwargs,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ThirdParty/diffusers/src/diffusers/models/controlnet.py:778\u001b[0m, in \u001b[0;36mControlNetModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, controlnet_cond, conditioning_scale, class_labels, timestep_cond, attention_mask, added_cond_kwargs, cross_attention_kwargs, guess_mode, return_dict)\u001b[0m\n\u001b[1;32m    775\u001b[0m     aug_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embedding(encoder_hidden_states)\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maddition_embed_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_time\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_embeds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m:\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    780\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has the config param `addition_embed_type` set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which requires the keyword argument `text_embeds` to be passed in `added_cond_kwargs`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m         )\n\u001b[1;32m    782\u001b[0m     text_embeds \u001b[38;5;241m=\u001b[39m added_cond_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "controlnet_results = controlnet(\n",
    "    # latent_model_input, \n",
    "    control_model_input,\n",
    "    timesteps[0],\n",
    "    # Recall image_embeds is the details of the face.\n",
    "    encoder_hidden_states=prompt_image_emb,\n",
    "    controlnet_cond=image,\n",
    "    #conditioning_scale=cond_scale\n",
    "    conditioning_scale=0.6,\n",
    "    # added_cond_kwargs=controlnet_added_cond_kwargs\n",
    "    #added_cond_kwargs=controlnet_added_cond_kwargs,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae44cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'prefer_nhwc': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_max_tuning_duration_ms': '0', 'use_ep_level_unified_stream': '0', 'tunable_op_enable': '0', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'tunable_op_tuning_enable': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'has_user_compute_stream': '0', 'gpu_mem_limit': '18446744073709551615', 'device_id': '0'}}\n",
      "find model: /Data/Models/Diffusion/InstantX/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ThirdParty/insightface/python-package/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    }
   ],
   "source": [
    "default_result = get_face_and_pose_info_from_images(\n",
    "    \"antelopev2\",\n",
    "    \"/Data/Models/Diffusion/InstantX\",\n",
    "    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"LennaSjööblom_LenaForsén\" / \"qShFGgyfM2o8OTptV6bGyf_9QVDc7x2ua38DJyWci9nsRi8u2ZJunn27MMP8vji6wZmUna5cR7TDxpC_p1wrzVinINlkVsl8tB6JY3RF81L9bAU38H4N-EQwDtEWWUT2.jpeg\",\n",
    "    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"TeddiSmith\" / \"tumblr_oythctEdBF1wykvxvo1_1280.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ffbeb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512,)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=472x699>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "699\n",
      "472\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=773x800>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "800\n",
      "773\n"
     ]
    }
   ],
   "source": [
    "print(type(default_result[0].face_embedding))\n",
    "print(default_result[0].face_embedding.shape)\n",
    "print(default_result[0].face_keypoints.show())\n",
    "print(default_result[0].height)\n",
    "print(default_result[0].width)\n",
    "print(default_result[1].pose_keypoints.show())\n",
    "print(default_result[1].height)\n",
    "print(default_result[1].width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f8b029",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_face_and_pose_info_from_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m original_default_det_result \u001b[38;5;241m=\u001b[39m \u001b[43mget_face_and_pose_info_from_images\u001b[49m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mantelopev2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Data/Models/Diffusion/InstantX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     data_sub_dirs\u001b[38;5;241m.\u001b[39mPublic \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlayboy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLennaSjööblom_LenaForsén\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqShFGgyfM2o8OTptV6bGyf_9QVDc7x2ua38DJyWci9nsRi8u2ZJunn27MMP8vji6wZmUna5cR7TDxpC_p1wrzVinINlkVsl8tB6JY3RF81L9bAU38H4N-EQwDtEWWUT2.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     data_sub_dirs\u001b[38;5;241m.\u001b[39mPublic \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlayboy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeddiSmith\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtumblr_oythctEdBF1wykvxvo1_1280.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     det_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_face_and_pose_info_from_images' is not defined"
     ]
    }
   ],
   "source": [
    "original_default_det_result = get_face_and_pose_info_from_images(\n",
    "    \"antelopev2\",\n",
    "    \"/Data/Models/Diffusion/InstantX\",\n",
    "    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"LennaSjööblom_LenaForsén\" / \"qShFGgyfM2o8OTptV6bGyf_9QVDc7x2ua38DJyWci9nsRi8u2ZJunn27MMP8vji6wZmUna5cR7TDxpC_p1wrzVinINlkVsl8tB6JY3RF81L9bAU38H4N-EQwDtEWWUT2.jpeg\",\n",
    "    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"TeddiSmith\" / \"tumblr_oythctEdBF1wykvxvo1_1280.jpg\",\n",
    "    det_size=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce65134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512,)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=472x699>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "699\n",
      "472\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=773x800>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "800\n",
      "773\n"
     ]
    }
   ],
   "source": [
    "print(type(default_result[0].face_embedding))\n",
    "print(default_result[0].face_embedding.shape)\n",
    "print(default_result[0].face_keypoints.show())\n",
    "print(default_result[0].height)\n",
    "print(default_result[0].width)\n",
    "print(default_result[1].pose_keypoints.show())\n",
    "print(default_result[1].height)\n",
    "print(default_result[1].width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b65110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_pose_information(model_name, model_root_directory, image_path):\n",
    "    \"\"\"\n",
    "    By creating an object for FaceAnalysisWrapper, which wraps FaceAnalysis, within this function, the\n",
    "    object goes out of scope once the function is done.\n",
    "    \"\"\"\n",
    "#    face_analysis_wrapper = FaceAnalysisWrapper(model_name, model_root_directory)\n",
    "#    pose_information = face_analysis_wrapper.get_pose_info_from_image(\n",
    "#        image_path)\n",
    "#    return pose_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50371de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pose_information = get_pose_information(\n",
    "#    \"antelopev2\",\n",
    "#    \"/Data/Models/Diffusion/InstantX\",\n",
    "#    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"TeddiSmith\" / \"U6S88ytE0BQ.jpg\")\n",
    "\n",
    "#print(type(pose_information))\n",
    "#print(type(pose_information.pose_keypoints))\n",
    "#print(pose_information.height)\n",
    "#print(pose_information.width)\n",
    "#pose_information.pose_keypoints.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15c86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_analysis_wrapper = FaceAnalysisWrapper(\"antelopev2\", \"/Data/Models/Diffusion/InstantX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e386bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pose_information = face_analysis_wrapper.get_pose_info_from_image(\n",
    "#    data_sub_dirs.Public / \"Images\" / \"Playboy\" / \"TeddiSmith\" / \"U6S88ytE0BQ.jpg\")\n",
    "#print(type(pose_information))\n",
    "#print(type(pose_information.pose_keypoints))\n",
    "#print(pose_information.height)\n",
    "#print(pose_information.width)\n",
    "#pose_information.pose_keypoints.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ebf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_inform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
