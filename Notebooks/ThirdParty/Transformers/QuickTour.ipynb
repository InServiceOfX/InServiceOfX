{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb5a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0a0+29c30b1\n",
      "True\n",
      "CUDA (GPU support) is available in this environment!\n"
     ]
    }
   ],
   "source": [
    "# Check to see if GPU is being used.\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU support) is available in this environment!\")\n",
    "else:\n",
    "    print(\"CUDA (GPU support) is NOT available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66ca396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ea875",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/quicktour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dae9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa87d16",
   "metadata": {},
   "source": [
    "Start by creating an instance of `pipeline()` and specify a task you want to use it for. e.g. use `pipeline()` for sentiment analysis as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca029521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acda09723ca14c2086fe9ff2fc0b2596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6892737f3b6046428164eeccac9e58ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3af55d88f474016a9a9e288de821f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f5bfe476d54501aa5d515421174425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec9e6b",
   "metadata": {},
   "source": [
    "The `pipeline()` downloads and caches a default pretrained model and tokenizer for sentiment analysis. Now you can use classifier on your target text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701790f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the  Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b846d26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the  Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5e1ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a374c037569c4fef94ab9e294b452048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4149c536014685ba20a535b6ce86da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785d43b1e346497cacdb2509dfedaae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c1feed61dd4088943deb3dc2e24009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d40e2a58274d7eadaa5761d0fe2eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484bf5b6c35944bcb6aa09e46087be54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf944aaf",
   "metadata": {},
   "source": [
    "Load an audio dataset to iterate over. For example, load [MlnDS-14](https://huggingface.co/datasets/PolyAI/minds14) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fa057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16ccbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d6cf3c1d4e44aa864f8cd35bacf642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c33001dae14694833a711f21b062b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3577cc63",
   "metadata": {},
   "source": [
    "You need to make sure sampling rate of dataset matches sampling rate [`facebook/wav2vec-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h) was trained on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ef34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e31f7",
   "metadata": {},
   "source": [
    "The audio files are automatically loaded and resampled when calling the \"audio\" column. Extract raw waveform arrays from first 4 samples and pass it as a list to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37943cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FODING HOW I'D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I THURN A JOIN A COUNT']\n"
     ]
    }
   ],
   "source": [
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34d7da",
   "metadata": {},
   "source": [
    "For larger datasets where inputs are big, you'll want to pass a generator instead of a list to load inputs into memory. Look at [pipeline API reference](https://huggingface.co/docs/transformers/main_classes/pipelines) for more information.\n",
    "\n",
    "### Use another model and tokenizer in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2e75a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:835: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# Pytorch, use AutoModelForSequenceClassification to load pretrained model, and associated tokenizer.\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157d9870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved model to the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Moved model to the GPU\")\n",
    "else:\n",
    "    print(\"Model still on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52253f",
   "metadata": {},
   "source": [
    "Specify the model and tokenizer in the `pipeline()` and now you can apply the classifier on French text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b2e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc51559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7272652387619019}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Nous sommes tr猫s heureux de vous pr茅senter la biblioth猫que  Transformers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca63cf9",
   "metadata": {},
   "source": [
    "If you can't find a model for your use-case, you'll need to finetune a pretrained model on your data.\n",
    "\n",
    "* [finetuning tutorial](https://huggingface.co/docs/transformers/training)\n",
    "\n",
    "# AutoClass\n",
    "\n",
    "[AutoClass](https://huggingface.co/docs/transformers/model_doc/auto) is a shortcut that automatically retrieves the architecture of a pretrained model from its name or path.\n",
    "\n",
    "The tokenizer returns a dictionary containing:\n",
    "* [input_ids](https://huggingface.co/docs/transformers/glossary#input-ids) numerical representations of your tokens\n",
    "* [attention_mask](https://huggingface.co/docs/transformers/.glossary#attention-mask) indicate which tokens should be attended to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fb7ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the  Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43744c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
      "         58263, 13299,   119,   102],\n",
      "        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n",
      "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# Pytorch\n",
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the  Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",)\n",
    "print(pt_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a90fa",
   "metadata": {},
   "source": [
    "Check out how to use an\n",
    "* [AutoImageProcessor](https://huggingface.co/docs/transformers/v4.36.1/en/model_doc/auto#transformers.AutoImageProcessor)\n",
    "* [AutoFeatureExtractor](https://huggingface.co/docs/transformers/v4.36.1/en/model_doc/auto#transformers.AutoFeatureExtractor)\n",
    "* [AutoProcessor](https://huggingface.co/docs/transformers/v4.36.1/en/model_doc/auto#transformers.AutoProcessor)\n",
    "\n",
    "to preprocess image, audio, and multimodal inputs.\n",
    "\n",
    "### AutoModel\n",
    "\n",
    "For text (or sequence) classification, you should load [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/v4.36.1/en/model_doc/auto#transformers.AutoModelForSequenceClassification)\n",
    "\n",
    "Pass preprocessed batch of inputs directly to the model. Unpack dictionary by adding **:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a881bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_outputs = model(**pt_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99423b",
   "metadata": {},
   "source": [
    "The model outputs the final activations in the logits attribute. Apply softmax function to retrieve probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d4c12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5da6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e73b7",
   "metadata": {},
   "source": [
    "#### Save a model\n",
    "\n",
    "Once your model is fine-tuned, you can save it with its tokenizer using [PreTrainedModel.save_pretrained()](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75de8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "031cc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When ready to use the model again, reload it\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5b8b9",
   "metadata": {},
   "source": [
    "#### Custom model builds\n",
    "\n",
    "You can modify the model's configuration class to change how a model is built. The configuration specifies a model's attributes, such as number of hidden layers or attention heads.You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you'll need to train the model before you can use it to get meaningful results.\n",
    "\n",
    "Within [`AutoConfig.from_pretrained()`](https://huggingface.co/docs/transformers/v4.36.1/en/model_doc/auto#transformers.AutoConfig.from_pretrained) you can specify attribute you want to change, such as number of attention heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ba319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d32e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca5593363d0460c8a04a9ac4c42f47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527c1f4",
   "metadata": {},
   "source": [
    "Create a model from your custom configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb31789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f6f3c",
   "metadata": {},
   "source": [
    "#### Trainer - a PyTorch optimized training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf25cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a645d53fdc447da508a3d8e9bc3363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Start with a PreTrainedModel or torch.nn.Module\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53e046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdae1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments contains the model hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./example_save_folder/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2)\n",
    "\n",
    "# Load preprocessing class like a tokenizer, image processor, feature extractor, or processor\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f164eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f59e5286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0442dc73715844a689dcb52458944fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9899b2fcd544e58022007d7622c6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805f31cea7c34fd08023cfc0db9ae887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a function to tokenize dataset.\n",
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "\n",
    "# Then apply it over entire dataset with map:\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataCollatorWithPadding to create a batch of examples from your dataset:\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5280479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89000821",
   "metadata": {},
   "source": [
    "Now gather all these classes in [Trainer](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e36fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator) # doctest: + SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65549601",
   "metadata": {},
   "source": [
    "When you're ready, call [`train()`](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.Trainer.train) to start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf71243",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 路路路路路路路路\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 路路路路路路路路\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/InServiceOfX/Notebooks/ThirdParty/Transformers/wandb/run-20240115_082604-9ul5hw25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ernestyalumni/huggingface/runs/9ul5hw25' target=\"_blank\">effortless-puddle-1</a></strong> to <a href='https://wandb.ai/ernestyalumni/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ernestyalumni/huggingface' target=\"_blank\">https://wandb.ai/ernestyalumni/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ernestyalumni/huggingface/runs/9ul5hw25' target=\"_blank\">https://wandb.ai/ernestyalumni/huggingface/runs/9ul5hw25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2134' max='2134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2134/2134 03:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.706700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.544500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 18.1 s, total: 3min 52s\n",
      "Wall time: 5min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2134, training_loss=0.6165462447419385, metrics={'train_runtime': 350.8161, 'train_samples_per_second': 48.629, 'train_steps_per_second': 6.083, 'total_flos': 389237040539508.0, 'train_loss': 0.6165462447419385, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4817c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
