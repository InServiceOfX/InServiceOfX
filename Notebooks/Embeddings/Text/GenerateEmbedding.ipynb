{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172cf2c1",
   "metadata": {},
   "source": [
    "### Setup Jupyter notebook\n",
    "Setup Jupyter notebook to use (Python) modules in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02bba063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/InServiceOfX\n",
      "Is CoreCode directory in sys.path? False\n",
      "Is notebook directory's ancestor in sys.path? False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "# Make this path be the project's \"base\" directory, so we can include modules\n",
    "notebook_directory_ancestor = Path.cwd().resolve().parent.parent.parent\n",
    "print(notebook_directory_ancestor)\n",
    "core_code_directory = notebook_directory_ancestor / \"CoreCode/\"\n",
    "embeddings_directory = notebook_directory_ancestor / \"Embeddings/\"\n",
    "is_core_code_directory_in_sys_path = str(core_code_directory) in sys.path\n",
    "is_notebook_directory_ancestor_in_sys_path = str(notebook_directory_ancestor) in sys.path\n",
    "print(\"Is CoreCode directory in sys.path?\", is_core_code_directory_in_sys_path)\n",
    "print(\"Is notebook directory's ancestor in sys.path?\", is_notebook_directory_ancestor_in_sys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cd8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_core_code_directory_in_sys_path:\n",
    "    sys.path.append(str(core_code_directory))\n",
    "    \n",
    "if not str(embeddings_directory) in sys.path:\n",
    "    sys.path.append(str(embeddings_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a991e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoreCode.Utilities.LoadEnvironmentFile import load_environment_file\n",
    "from Embeddings.Text.GenerateEmbedding import (\n",
    "    GenerateEmbedding,\n",
    "    GenerateEmbeddingFromHuggingFaceMiniLM,\n",
    "    QueryHuggingFaceFeatureExtraction)\n",
    "load_environment_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599f504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "# Uncomment out if you want it printed in plain-text.\n",
    "# print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f1e8e",
   "metadata": {},
   "source": [
    "See [Vector Search RAG Tutorial - Combine Your Data with LLMs with Advanced Search](https://youtu.be/JEBDfGqrAUA?si=s4alDYXsp9eXCKwY), by [freeCodeCamp.org](https://www.youtube.com/@freecodecamp) for the tutorial we had followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fae980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2\n",
      "https://api-inference.huggingface.co/pipeline/feature-extraction/\n"
     ]
    }
   ],
   "source": [
    "# Uncomment out print command for debugging.\n",
    "print(GenerateEmbeddingFromHuggingFaceMiniLM.MINILM_API_URL)\n",
    "print(QueryHuggingFaceFeatureExtraction.PIPELINE_URL)\n",
    "generator = GenerateEmbedding(token, GenerateEmbeddingFromHuggingFaceMiniLM.MINILM_API_URL)\n",
    "query_feature_extraction = QueryHuggingFaceFeatureExtraction(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e53ffbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "query = \"freeCodeCamp is awesome\"\n",
    "generate_result = generator.generate_embedding(query)\n",
    "print(type(generate_result))\n",
    "print(len(generate_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1676254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "384\n",
      "[-0.04656720161437988, -0.10088976472616196, 0.023876406252384186, 0.03345140069723129, 0.04757402837276459, 0.009101650677621365, -0.01100260391831398, -0.055370427668094635, -0.00289178011007607, 0.033230096101760864, 0.04593603312969208, 0.02030876651406288, -0.018762925639748573, 0.022110996767878532, 0.014108472503721714, 0.019433695822954178, -0.002060073195025325, 0.04771622642874718, 0.028062671422958374, -0.04205813631415367]\n"
     ]
    }
   ],
   "source": [
    "query_feature_extraction = QueryHuggingFaceFeatureExtraction(token)\n",
    "query_result = query_feature_extraction.query_feature_extraction(query)\n",
    "print(type(query_result))\n",
    "print(len(query_result))\n",
    "print(query_result[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fe1a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(generate_result == query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30239120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
