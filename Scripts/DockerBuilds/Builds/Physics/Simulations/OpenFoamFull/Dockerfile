# This Dockerfile is automatically generated by con(cat)enating textfiles. It's
# automatically concatenated by running a shell script (e.g.
# SetupPyTorchGPUDocker.sh) or doing something like, in command line,
# cat Dockerfile.header Dockerfile.base ..


# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/running.html
# Also, see
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch
# Check for the latest version on this page, on the left:
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/running.html
# Look for the PyTorch Release Notes.
# Also, try
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags
# and click on "Tags" on the top center for the different tags.

# As of March 26, 2024, there's 24.03.
# By doing nvcc --version, one can see that from 24.03, CUDA is 12.4. From
# 24.02, CUDA is 12.3.r12.3. For OpenCV and this issue, let's stay with < 12.4.
# Issue: https://github.com/opencv/opencv_contrib/issues/3690
# Furthermore, cudnnRNNForwardInference was removed in 9.0 of cuDNN:
# https://docs.nvidia.com/deeplearning/cudnn/api/overview.html
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-01.html
ARG BASE_IMAGE
FROM ${BASE_IMAGE}

# Set the working directory in the container
# https://docs.docker.com/engine/reference/builder/
ENV THIRD_PARTY=/ThirdParty
WORKDIR /

## Update apt, pip, and do pip installs.
RUN apt-get update && \
  apt-get install --upgrade -y ccache && \
  python -m pip install --upgrade pip && \
  #
  #
  # Do more pip installs.
  # Reads key-value pairs from .env file to set environment variables; in
  # particular for Open AI API keys for LangChain.
  pip install --upgrade python-dotenv




# Install Rust
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y && \
  # https://rust-lang.github.io/rustup/installation/index.html
  # export PATH once, doing both Rust and poetry binaries.
  echo "export PATH=/root/.cargo/bin:$PATH" >> $HOME/.bashrc



# https://openfoam.org/download/source/

# https://openfoam.org/download/source/software-for-compilation/
# openfoam-nopv-deps
RUN apt-get update && apt-get install -y build-essential git ca-certificates flex \
  libopenmpi-dev openmpi-bin openmpi-common zlib1g-dev gnuplot gnuplot-x11 libxt-dev
# openfoam-deps:
RUN apt-get install -y libxml2-dev libhdf5-dev libavfilter-dev libtheora-dev \
  libgl2ps-dev libx11-dev libqt5x11extras5-dev libglew-dev libutfcpp-dev \
  libdouble-conversion-dev libfreetype-dev libqt5svg5-dev \
  qtxmlpatterns5-dev-tools qttools5-dev python3-dev \
  # Ubuntu 24.04 only
  libadios2-serial-c-dev libadios2-serial-c++11-dev

# https://openfoam.org/download/source/software-for-compilation/
# "ParaView development package (in order to compile anything relating to
# ParaView)."
RUN apt install -y paraview-dev

# OpenFOAM-dev: the current development line of OpenFOAM, that contains the
# source code for the next major release of OpenFOAM.
RUN git clone https://github.com/OpenFOAM/OpenFOAM-dev.git /ThirdParty/OpenFOAM-dev && \
  cd /ThirdParty/OpenFOAM-dev && \
  # master branch, commit on Dec 19, 2025
  git checkout 87f81af68759c274b657e98f73d76f8e40354eb1 && \
  cd /

# https://openfoam.org/download/source/downloading-source-code/
RUN git clone https://github.com/OpenFOAM/ThirdParty-dev.git /ThirdParty/ThirdParty-dev && \
  cd /ThirdParty/ThirdParty-dev && \
  # master branch, commit on Dec 19, 2025
  git checkout e208aac90b13ed3c1cf96ec2d29282adeeb55338 && \
  cd /

# Set up OpenFOAM environment for both build-time and runtime
# Source the bashrc file to set up environment variables
RUN echo "source /ThirdParty/OpenFOAM-dev/etc/bashrc" >> $HOME/.bashrc

# Also set it up for non-interactive shells (Docker RUN commands)
# This ensures environment is available during build
ENV WM_PROJECT_DIR=/ThirdParty/OpenFOAM-dev
# Set environment variables explicitly to ensure OpenFOAM finds everything
ENV WM_THIRD_PARTY_DIR=/ThirdParty/ThirdParty-dev

# Set MPI environment variables to help configure scripts find MPI
# Find MPI installation path and set variables accordingly
# The NVIDIA PyTorch base image has MPI at /usr/local/mpi
RUN MPI_PATH=$(dirname $(dirname $(which mpicc))) 2>/dev/null || MPI_PATH=/usr/local/mpi && \
  echo "MPI found at: $MPI_PATH" && \
  echo "export MPI_ARCH_PATH=$MPI_PATH" >> $HOME/.bashrc && \
  echo "export MPI_HOME=$MPI_PATH" >> $HOME/.bashrc

# Verify MPI installation before building
#RUN which mpicc && which mpicxx && test -f /usr/include/mpi.h && echo "MPI installation verified"
# Find mpi.h wherever it is (could be in /usr/local/mpi/include or /usr/include)
RUN which mpicc && which mpicxx && \
  (test -f /usr/local/mpi/include/mpi.h || test -f /usr/include/mpi.h || find /usr -name mpi.h 2>/dev/null | head -1) && \
  echo "MPI installation verified"

# https://openfoam.org/download/source/compiling-openfoam/
# It can also compile multiple libraries and executables simultaneously with the
# -q option.
# Need to source OpenFOAM bashrc as each RUN command in Docker starts a fresh
# shell.
# Use the MPI path from the NVIDIA base image
# IMPORTANT: Set WM_PROJECT_DIR and WM_THIRD_PARTY_DIR BEFORE sourcing bashrc
RUN bash -c "\
  source /ThirdParty/OpenFOAM-dev/etc/bashrc && \
  export CPATH=/usr/local/mpi/include:\$CPATH && \
  export LIBRARY_PATH=/usr/local/mpi/lib:\$LIBRARY_PATH && \
  export LD_LIBRARY_PATH=/usr/local/mpi/lib:\$LD_LIBRARY_PATH && \
  cd /ThirdParty/OpenFOAM-dev && \
  ./Allwmake -q -j\$(nproc)"
