# This Dockerfile is automatically generated by con(cat)enating textfiles. It's
# automatically concatenated by running a shell script (e.g.
# SetupPyTorchGPUDocker.sh) or doing something like, in command line,
# cat Dockerfile.header Dockerfile.base ..


# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/running.html
# Also, see
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch
# Check for the latest version on this page, on the left:
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/running.html
# Look for the PyTorch Release Notes.
# Also, try
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags
# and click on "Tags" on the top center for the different tags.

# As of March 26, 2024, there's 24.03.
# By doing nvcc --version, one can see that from 24.03, CUDA is 12.4. From
# 24.02, CUDA is 12.3.r12.3. For OpenCV and this issue, let's stay with < 12.4.
# Issue: https://github.com/opencv/opencv_contrib/issues/3690
# Furthermore, cudnnRNNForwardInference was removed in 9.0 of cuDNN:
# https://docs.nvidia.com/deeplearning/cudnn/api/overview.html
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-01.html
ARG BASE_IMAGE
FROM ${BASE_IMAGE}

# Set the working directory in the container
# https://docs.docker.com/engine/reference/builder/
ENV THIRD_PARTY=/ThirdParty
ENV PATH="/opt/venv/bin:/root/.cargo/bin:$PATH"
WORKDIR /

## Update apt, pip, and do pip installs.
RUN apt-get update && \
  apt-get install --upgrade -y ccache && \
  python -m pip install --upgrade pip && \
  #
  # Do more pip installs.
  # Reads key-value pairs from .env file to set environment variables; in
  # particular for Open AI API keys for LangChain.
  pip install --upgrade python-dotenv


# ## Update apt, pip, and do pip installs.
# RUN apt-get update && \
#   apt-get install --upgrade -y ccache python3 python3-pip python3-venv curl \
#     git && rm -rf /var/lib/apt/lists/*

# RUN python3 -m venv /opt/venv

# RUN /opt/venv/bin/pip install --upgrade pip






# Install Rust
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y && \
  # https://rust-lang.github.io/rustup/installation/index.html
  # export PATH once, doing both Rust and poetry binaries.
  echo "export PATH=/root/.cargo/bin:$PATH" >> $HOME/.bashrc



# See
# https://docs.sglang.ai/start/install.html#method-2-from-source
# TODO: Consider installing FlashInfer from source for AOT mode for production.
# https://docs.flashinfer.ai/installation.html

# Originally, the documentation said to install by cloning this specific version:
# git clone -b v0.5.2rc0 https://github.com/sgl-project/sglang.git
RUN git clone https://github.com/sgl-project/sglang.git /ThirdParty/sglang && \
    cd /ThirdParty/sglang && \
    git checkout v0.5.2rc0 && \
    pip install --upgrade pip && \
    pip install -e "python[all]"




## HuggingFace

RUN python3 -m pip install --upgrade pip && \
  # Upgrading Jinja2 to 3.1 is needed to use apply_chat_template.
  pip install --upgrade jinja2 && \
  #
  #
  pip install tokenizers

### Further third party code/repositories

#
#
# InServiceOfX
#
#
RUN git clone --no-checkout https://github.com/InServiceOfX/InServiceOfX.git /ThirdParty/InServiceOfX && \
  cd /ThirdParty/InServiceOfX/ && \
  git sparse-checkout init && \
  git sparse-checkout add PythonApplications/CLIChatLocal && \
  git sparse-checkout add PythonLibraries/CoreCode && \
  git sparse-checkout add PythonLibraries/HuggingFace/MoreTransformers && \
  git sparse-checkout add PythonLibraries/ThirdParties/APIs/CommonAPI && \
  git sparse-checkout add PythonLibraries/ThirdParties/APIs/MoreSGLang && \
  git checkout master && \
  cd /

RUN pip install pydantic

RUN apt-get update && apt-get install -y libnuma-dev

#
#
#






RUN pip install --upgrade pytest python-dotenv



