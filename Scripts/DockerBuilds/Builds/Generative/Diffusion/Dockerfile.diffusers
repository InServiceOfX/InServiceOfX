## HuggingFace

## transformers (hugging face), required to run most popular diffusion models.
RUN git clone https://github.com/huggingface/transformers.git /ThirdParty/transformers && \
  cd /ThirdParty/transformers && \
  # We used to checkout main, but now we'd like to control versions better.
  #git checkout main && \
  # From
  # stabilityai/sdxl-turbo/text_encoder/config.json
  #   "transformers_version": "4.36.0.dev0".
  # TODO: But, "downstream", later in the steps of building the Docker image,
  # transformers gets upgraded to the latest tag; investigate if this is what
  # we want and where it happens. Also, the latest nunchaku, since about v.1,0.1
  # doesn't allow for transformers, v4.36.1, it raises compatibility error.
  git checkout v4.57.0 && \
  # Install editable install from source.
  # See https://huggingface.co/docs/transformers/installation#installing-from-source
  pip install -e . && \
  #
  #
## diffusers (hugging face)
  git clone https://github.com/InServiceOfX/diffusers.git /ThirdParty/diffusers && \
  cd /ThirdParty/diffusers && \
  # We used to checkout master, but now we'd like to control versions better.
  #git checkout master && \
  #git config --local pull.rebase true && \
  #git pull origin master && \
  git checkout v0.35.2-b60ab1f82 && \
  pip install -e . && \
  # TODO: This is needed, because "from_slow" tokenizer.json field of
  # FluxPipeline models. Consider
  # https://discuss.huggingface.co/t/value-error-sentencepiece/4313/6
  pip install sentencepiece && \
  #
  #
## accelerate - speeds up model loading for inference and training
  git clone https://github.com/huggingface/accelerate.git /ThirdParty/accelerate && \
  cd /ThirdParty/accelerate && \
  git checkout main && \
  pip install -e . && \
  #
  #
## candle (hugging face)
  git clone https://github.com/huggingface/candle.git /ThirdParty/candle && \
  cd /ThirdParty/candle && \
  git checkout main && \
  #
  #
## PEFT (Parameter-Efficient Fine-Tuning)
  git clone https://github.com/huggingface/peft /ThirdParty/peft && \
  cd /ThirdParty/peft && \
  pip install -e . && \
  #
  #
## For JAX/Flax
  # Even if jax jaxlib are updated to 0.4.X and same version, you obtain
  # AttributeError: partially initialized module 'jax' has no attribute
  # 'version' (most likely due to a circular import)
  #pip install --upgrade jax && \
  # Even if you do the option --upgrade, this makes it so that jax is 0.2.X and
  # it's too old.
  #pip install --upgrade "jax[cuda]" -f https://storage.googleapis.com/jax-releases/jax_releases.html && \
  #pip install --upgrade jaxlib && \
  # This fix was from here:
  # https://github.com/google/jax/discussions/14036#discussioncomment-8717604 
  #pip install -U "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html && \
  #pip install flax && \
  # https://github.com/google/jax/blob/main/README.md#instructions
  #
  pip install -U "jax[cuda12]" && \
  # https://huggingface.co/docs/diffusers/en/optimization/onnx
  # Optimum provides at Stable Diffusion pipeline compatible with ONNX Runtime.
  #python -m pip install optimum[onnxruntime,quanto]@git+https://github.com/huggingface/optimum.git && \
  #cd /
  pip install optimum-quanto && \
  cd /



