## HuggingFace

## transformers (hugging face), required to run most popular diffusion models.
RUN git clone https://github.com/huggingface/transformers.git /ThirdParty/transformers && \
  cd /ThirdParty/transformers && \
  git checkout main && \
  # Install editable install from source.
  # See https://huggingface.co/docs/transformers/installation#installing-from-source
  pip install -e . && \
  #
  #
## diffusers (hugging face)
  git clone https://github.com/InServiceOfX/diffusers.git /ThirdParty/diffusers && \
  cd /ThirdParty/diffusers && \
  git checkout master && \
  git config --local pull.rebase true && \
  git pull origin master && \
  pip install -e . && \
  # TODO: This is needed, because "from_slow" tokenizer.json field of
  # FluxPipeline models. Consider
  # https://discuss.huggingface.co/t/value-error-sentencepiece/4313/6
  pip install sentencepiece && \
  #
  #
## accelerate - speeds up model loading for inference and training
  git clone https://github.com/huggingface/accelerate.git /ThirdParty/accelerate && \
  cd /ThirdParty/accelerate && \
  git checkout main && \
  pip install -e . && \
  #
  #
## candle (hugging face)
  git clone https://github.com/InServiceOfX/candle.git /ThirdParty/candle && \
  cd /ThirdParty/candle && \
  git checkout master && \
  #
  #
## PEFT (Parameter-Efficient Fine-Tuning)
  git clone https://github.com/huggingface/peft /ThirdParty/peft && \
  cd /ThirdParty/peft && \
  pip install -e . && \
  #
  #
## For JAX/Flax
  # Even if jax jaxlib are updated to 0.4.X and same version, you obtain
  # AttributeError: partially initialized module 'jax' has no attribute
  # 'version' (most likely due to a circular import)
  #pip install --upgrade jax && \
  # Even if you do the option --upgrade, this makes it so that jax is 0.2.X and
  # it's too old.
  #pip install --upgrade "jax[cuda]" -f https://storage.googleapis.com/jax-releases/jax_releases.html && \
  #pip install --upgrade jaxlib && \
  # This fix was from here:
  # https://github.com/google/jax/discussions/14036#discussioncomment-8717604 
  #pip install -U "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html && \
  #pip install flax && \
  # https://github.com/google/jax/blob/main/README.md#instructions
  #
  pip install -U "jax[cuda12]" && \
  # https://huggingface.co/docs/diffusers/en/optimization/onnx
  # Optimum provides at Stable Diffusion pipeline compatible with ONNX Runtime.
  python -m pip install optimum[onnxruntime]@git+https://github.com/huggingface/optimum.git && \
  cd /




