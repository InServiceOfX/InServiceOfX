# This Dockerfile is automatically generated by con(cat)enating textfiles. It's
# automatically concatenated by running a shell script (e.g.
# SetupPyTorchGPUDocker.sh) or doing something like, in command line,
# cat Dockerfile.header Dockerfile.base ..


# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/running.html
# Also, see
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch
# Check for the latest version on this page, on the left:
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/running.html
# Look for the PyTorch Release Notes.
# Also, try
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags
# and click on "Tags" on the top center for the different tags.

# As of March 26, 2024, there's 24.03.
# By doing nvcc --version, one can see that from 24.03, CUDA is 12.4. From
# 24.02, CUDA is 12.3.r12.3. For OpenCV and this issue, let's stay with < 12.4.
# Issue: https://github.com/opencv/opencv_contrib/issues/3690
# Furthermore, cudnnRNNForwardInference was removed in 9.0 of cuDNN:
# https://docs.nvidia.com/deeplearning/cudnn/api/overview.html
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-01.html
ARG BASE_IMAGE
FROM ${BASE_IMAGE}

# Set the working directory in the container
# https://docs.docker.com/engine/reference/builder/
ENV THIRD_PARTY=/ThirdParty
WORKDIR /

## Update apt, pip, and do pip installs.
RUN apt-get update && \
  apt-get install --upgrade -y ccache && \
  python -m pip install --upgrade pip && \
  #
  #
  # Do more pip installs.
  # Reads key-value pairs from .env file to set environment variables; in
  # particular for Open AI API keys for LangChain.
  pip install --upgrade python-dotenv





## HuggingFace

## transformers (hugging face), required to run most popular diffusion models.
RUN git clone https://github.com/huggingface/transformers.git /ThirdParty/transformers && \
  cd /ThirdParty/transformers && \
  # main branch, Commits on Nov 15, 2025
  git checkout 66d57110f089789ae285cc9d54d3bf051123246b && \
  # Install editable install from source.
  # See https://huggingface.co/docs/transformers/installation#installing-from-source
  pip install -e . && \
  #
  #
## diffusers (hugging face)
#   git clone https://github.com/InServiceOfX/diffusers.git /ThirdParty/diffusers && \
#   cd /ThirdParty/diffusers && \
#   git checkout master && \
#   git config --local pull.rebase true && \
#   git pull origin master && \
#   pip install -e . && \
#   # TODO: This is needed, because "from_slow" tokenizer.json field of
#   # FluxPipeline models. Consider
#   # https://discuss.huggingface.co/t/value-error-sentencepiece/4313/6
#   pip install sentencepiece && \
#   #
#   #
# ## accelerate - speeds up model loading for inference and training
#   git clone https://github.com/huggingface/accelerate.git /ThirdParty/accelerate && \
#   cd /ThirdParty/accelerate && \
#   git checkout main && \
#   pip install -e . && \
#   #
#   #
# ## candle (hugging face)
#   git clone https://github.com/huggingface/candle.git /ThirdParty/candle && \
#   cd /ThirdParty/candle && \
#   git checkout main && \
#   #
#   #
# ## PEFT (Parameter-Efficient Fine-Tuning)
#   git clone https://github.com/huggingface/peft /ThirdParty/peft && \
#   cd /ThirdParty/peft && \
#   pip install -e . && \
#   #
#   #
# ## For JAX/Flax
#   # Even if jax jaxlib are updated to 0.4.X and same version, you obtain
#   # AttributeError: partially initialized module 'jax' has no attribute
#   # 'version' (most likely due to a circular import)
#   #pip install --upgrade jax && \
#   # Even if you do the option --upgrade, this makes it so that jax is 0.2.X and
#   # it's too old.
#   #pip install --upgrade "jax[cuda]" -f https://storage.googleapis.com/jax-releases/jax_releases.html && \
#   #pip install --upgrade jaxlib && \
#   # This fix was from here:
#   # https://github.com/google/jax/discussions/14036#discussioncomment-8717604 
#   #pip install -U "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html && \
#   #pip install flax && \
#   # https://github.com/google/jax/blob/main/README.md#instructions
#   #
#   pip install -U "jax[cuda12]" && \
#   # https://huggingface.co/docs/diffusers/en/optimization/onnx
#   # Optimum provides at Stable Diffusion pipeline compatible with ONNX Runtime.
#   #python -m pip install optimum[onnxruntime,quanto]@git+https://github.com/huggingface/optimum.git && \
#   #cd /
#   pip install optimum-quanto && \
  cd /




